<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>SQL Support</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>SQL Support</h1>
<blockquote>原文：<a href="https://howqueryengineswork.com/07-sql-support.html">https://howqueryengineswork.com/07-sql-support.html</a></blockquote>
                        
<p><em>The source code discussed in this chapter can be found in the <code>sql</code> module of the <a href="https://github.com/andygrove/how-query-engines-work">KQuery project</a>.</em></p>
<p>The previous chapter showed how to build queries using the DataFrame API. But most users expect to write SQL. This chapter covers parsing SQL text into a logical plan, which involves two steps: parsing (text to syntax tree) and planning (syntax tree to logical plan).</p>
<h2 id="the-journey-from-sql-to-logical-plan"><a class="header" href="#the-journey-from-sql-to-logical-plan">The Journey from SQL to Logical Plan</a></h2>
<p>Consider this query:</p>
<pre><code class="language-sql">SELECT id, first_name, salary * 1.1 AS new_salary
FROM employee
WHERE state = 'CO'
</code></pre>
<p>To execute this, we need to:</p>
<ol>
<li>Tokenize: Break the text into tokens (keywords, identifiers, literals, operators)</li>
<li>Parse: Build a syntax tree that represents the query structure</li>
<li>Plan: Convert the syntax tree into a logical plan</li>
</ol>
<p>The result is the same logical plan we could build with the DataFrame API, but constructed from SQL text instead of code.</p>
<h2 id="tokenizing"><a class="header" href="#tokenizing">Tokenizing</a></h2>
<p>The tokenizer (or lexer) converts a string into a sequence of tokens. Each token has a type and a value.</p>
<pre><code class="language-kotlin">data class Token(val text: String, val type: TokenType, val endOffset: Int)
</code></pre>
<p>Token types include:</p>
<ul>
<li>Keywords: <code>SELECT</code>, <code>FROM</code>, <code>WHERE</code>, <code>AND</code>, <code>OR</code>, etc.</li>
<li>Identifiers: table names, column names</li>
<li>Literals: strings (<code>'hello'</code>), numbers (<code>42</code>, <code>3.14</code>)</li>
<li>Symbols: operators and punctuation (<code>+</code>, <code>-</code>, <code>*</code>, <code>/</code>, <code>=</code>, <code>&lt;</code>, <code>&gt;</code>, <code>(</code>, <code>)</code>, <code>,</code>)</li>
</ul>
<p>For the query <code>SELECT a + b FROM c</code>, tokenizing produces:</p>
<pre><code class="language-kotlin">listOf(
    Token("SELECT", Keyword.SELECT, ...),
    Token("a", Literal.IDENTIFIER, ...),
    Token("+", Symbol.PLUS, ...),
    Token("b", Literal.IDENTIFIER, ...),
    Token("FROM", Keyword.FROM, ...),
    Token("c", Literal.IDENTIFIER, ...)
)
</code></pre>
<p>The tokenizer handles details like recognizing that <code>SELECT</code> is a keyword but <code>employee</code> is an identifier, parsing string literals with their quotes, and recognizing multi-character operators like <code>&lt;=</code> and <code>!=</code>.</p>
<h2 id="parsing-with-pratt-parsers"><a class="header" href="#parsing-with-pratt-parsers">Parsing with Pratt Parsers</a></h2>
<p>Parsing turns tokens into a tree structure. The challenge is handling operator precedence correctly. In <code>1 + 2 * 3</code>, multiplication binds tighter than addition, so the result should be <code>1 + (2 * 3)</code>, not <code>(1 + 2) * 3</code>.</p>
<p>KQuery uses a Pratt parser, based on Vaughan Pratt’s 1973 paper “Top Down Operator Precedence”. Pratt parsers handle precedence elegantly and produce clear, debuggable code.</p>
<p>The core algorithm is remarkably simple:</p>
<pre><code class="language-kotlin">interface PrattParser {

    fun parse(precedence: Int = 0): SqlExpr? {
        var expr = parsePrefix() ?: return null
        while (precedence &lt; nextPrecedence()) {
            expr = parseInfix(expr, nextPrecedence())
        }
        return expr
    }

    fun nextPrecedence(): Int
    fun parsePrefix(): SqlExpr?
    fun parseInfix(left: SqlExpr, precedence: Int): SqlExpr
}
</code></pre>
<p>The algorithm:</p>
<ol>
<li>Parse a “prefix” expression (a literal, identifier, or unary operator)</li>
<li>While the next operator has higher precedence than what we started with, parse it as an “infix” expression (binary operator) with the current expression as the left side</li>
<li>Return when we hit a lower-precedence operator</li>
</ol>
<p>The magic is in <code>parseInfix</code>, which recursively calls <code>parse</code> with the new operator’s precedence. This naturally groups higher-precedence operations first.</p>
<h2 id="sql-expressions"><a class="header" href="#sql-expressions">SQL Expressions</a></h2>
<p>The parser builds a syntax tree using SQL expression types:</p>
<pre><code class="language-kotlin">interface SqlExpr

data class SqlIdentifier(val id: String) : SqlExpr
data class SqlString(val value: String) : SqlExpr
data class SqlLong(val value: Long) : SqlExpr
data class SqlDouble(val value: Double) : SqlExpr
data class SqlBinaryExpr(val l: SqlExpr, val op: String, val r: SqlExpr) : SqlExpr
data class SqlAlias(val expr: SqlExpr, val alias: SqlIdentifier) : SqlExpr
data class SqlFunction(val name: String, val args: List&lt;SqlExpr&gt;) : SqlExpr
</code></pre>
<p>These mirror logical expressions but stay closer to SQL syntax. We use a generic <code>SqlBinaryExpr</code> with a string operator rather than separate classes for each operator since the distinctions matter more in the logical plan.</p>
<h2 id="precedence-in-action"><a class="header" href="#precedence-in-action">Precedence in Action</a></h2>
<p>Consider parsing <code>1 + 2 * 3</code>:</p>
<pre><code>Tokens:      [1]  [+]  [2]  [*]  [3]
Precedence:   0   50    0   60    0
</code></pre>
<p>Addition has precedence 50, multiplication has 60. Walking through:</p>
<ol>
<li>Parse prefix: <code>SqlLong(1)</code></li>
<li>Next token <code>+</code> has precedence 50 &gt; 0, so parse infix</li>
<li>In <code>parseInfix</code>, consume <code>+</code>, then recursively call <code>parse(50)</code></li>
<li>Parse prefix: <code>SqlLong(2)</code></li>
<li>Next token <code>*</code> has precedence 60 &gt; 50, so parse infix</li>
<li>Consume <code>*</code>, recursively call <code>parse(60)</code></li>
<li>Parse prefix: <code>SqlLong(3)</code></li>
<li>No more tokens, return <code>SqlLong(3)</code></li>
<li>Return <code>SqlBinaryExpr(SqlLong(2), "*", SqlLong(3))</code></li>
<li>Next precedence is 0 &lt; 50, so return</li>
<li>Return <code>SqlBinaryExpr(SqlLong(1), "+", SqlBinaryExpr(...))</code></li>
</ol>
<p>Result: <code>1 + (2 * 3)</code>, as expected.</p>
<p>Compare with <code>1 * 2 + 3</code>:</p>
<pre><code>Tokens:      [1]  [*]  [2]  [+]  [3]
Precedence:   0   60    0   50    0
</code></pre>
<ol>
<li>Parse prefix: <code>SqlLong(1)</code></li>
<li><code>*</code> has precedence 60 &gt; 0, parse infix</li>
<li>Consume <code>*</code>, call <code>parse(60)</code></li>
<li>Parse prefix: <code>SqlLong(2)</code></li>
<li><code>+</code> has precedence 50 &lt; 60, so return <code>SqlLong(2)</code></li>
<li>Return <code>SqlBinaryExpr(SqlLong(1), "*", SqlLong(2))</code></li>
<li><code>+</code> has precedence 50 &gt; 0, parse infix</li>
<li>Consume <code>+</code>, call <code>parse(50)</code></li>
<li>Parse prefix: <code>SqlLong(3)</code></li>
<li>No more tokens, return</li>
<li>Return <code>SqlBinaryExpr(SqlBinaryExpr(...), "+", SqlLong(3))</code></li>
</ol>
<p>Result: <code>(1 * 2) + 3</code>, correct again.</p>
<h2 id="parsing-select-statements"><a class="header" href="#parsing-select-statements">Parsing SELECT Statements</a></h2>
<p>Beyond expressions, we need to parse complete SQL statements. A SELECT statement has the following structure:</p>
<pre><code class="language-kotlin">data class SqlSelect(
    val projection: List&lt;SqlExpr&gt;,
    val tableName: String,
    val selection: SqlExpr?,
    val groupBy: List&lt;SqlExpr&gt;,
    val having: SqlExpr?,
    val orderBy: List&lt;SqlSort&gt;,
    val limit: Int?
) : SqlRelation
</code></pre>
<p>Parsing a SELECT statement is straightforward procedural code: expect <code>SELECT</code>, parse a comma-separated list of expressions, expect <code>FROM</code>, parse the table name, optionally parse <code>WHERE</code> and its expression, and so on.</p>
<h2 id="sql-planning-the-hard-part"><a class="header" href="#sql-planning-the-hard-part">SQL Planning: The Hard Part</a></h2>
<p>Parsing is mechanical. Planning is where things get interesting.</p>
<p>Consider this query:</p>
<pre><code class="language-sql">SELECT id, first_name, salary/12 AS monthly_salary
FROM employee
WHERE state = 'CO' AND monthly_salary &gt; 1000
</code></pre>
<p>The WHERE clause references both <code>state</code> (a column from the table) and <code>monthly_salary</code> (an alias defined in the SELECT list). This is natural for humans but creates a problem: the filter needs columns that exist at different points in the plan.</p>
<p>If we filter before projecting, <code>monthly_salary</code> does not exist yet. If we filter after projecting, <code>state</code> may no longer be available.</p>
<h3 id="solution-intermediate-projections"><a class="header" href="#solution-intermediate-projections">Solution: Intermediate Projections</a></h3>
<p>One approach adds columns to an intermediate projection:</p>
<pre><code>Projection: #id, #first_name, #monthly_salary
    Filter: #state = 'CO' AND #monthly_salary &gt; 1000
        Projection: #id, #first_name, #salary/12 AS monthly_salary, #state
            Scan: employee
</code></pre>
<p>The inner projection computes all needed columns including <code>state</code>. The filter can then reference everything. The outer projection removes <code>state</code> from the final output.</p>
<h3 id="translation-logic"><a class="header" href="#translation-logic">Translation Logic</a></h3>
<p>The planner walks the SQL expression tree and builds logical expressions:</p>
<pre><code class="language-kotlin">fun createLogicalExpr(expr: SqlExpr, input: LogicalPlan): LogicalExpr {
    return when (expr) {
        is SqlIdentifier -&gt; Column(expr.id)
        is SqlString -&gt; LiteralString(expr.value)
        is SqlLong -&gt; LiteralLong(expr.value)
        is SqlDouble -&gt; LiteralDouble(expr.value)
        is SqlAlias -&gt; Alias(createLogicalExpr(expr.expr, input), expr.alias.id)
        is SqlBinaryExpr -&gt; {
            val l = createLogicalExpr(expr.l, input)
            val r = createLogicalExpr(expr.r, input)
            when (expr.op) {
                "=" -&gt; Eq(l, r)
                "!=" -&gt; Neq(l, r)
                "&gt;" -&gt; Gt(l, r)
                "&gt;=" -&gt; GtEq(l, r)
                "&lt;" -&gt; Lt(l, r)
                "&lt;=" -&gt; LtEq(l, r)
                "AND" -&gt; And(l, r)
                "OR" -&gt; Or(l, r)
                "+" -&gt; Add(l, r)
                "-" -&gt; Subtract(l, r)
                "*" -&gt; Multiply(l, r)
                "/" -&gt; Divide(l, r)
                else -&gt; throw SQLException("Unknown operator: ${expr.op}")
            }
        }
        else -&gt; throw SQLException("Unsupported expression: $expr")
    }
}
</code></pre>
<h3 id="finding-column-references"><a class="header" href="#finding-column-references">Finding Column References</a></h3>
<p>To determine which columns the filter needs, we walk the expression tree:</p>
<pre><code class="language-kotlin">fun findColumnReferences(expr: LogicalExpr, columns: MutableSet&lt;String&gt;) {
    when (expr) {
        is Column -&gt; columns.add(expr.name)
        is Alias -&gt; findColumnReferences(expr.expr, columns)
        is BinaryExpr -&gt; {
            findColumnReferences(expr.l, columns)
            findColumnReferences(expr.r, columns)
        }
    }
}
</code></pre>
<p>With this, the planner can compare columns in the filter against columns in the projection and add any missing ones to the intermediate projection.</p>
<h2 id="aggregate-queries"><a class="header" href="#aggregate-queries">Aggregate Queries</a></h2>
<p>Aggregate queries add more complexity. Consider:</p>
<pre><code class="language-sql">SELECT department, AVG(salary) AS avg_salary
FROM employee
WHERE state = 'CO'
GROUP BY department
HAVING avg_salary &gt; 50000
</code></pre>
<p>The planner must:</p>
<ol>
<li>Identify aggregate functions (<code>AVG</code>)</li>
<li>Separate grouping expressions (<code>department</code>) from aggregates</li>
<li>Handle HAVING, which filters after aggregation</li>
<li>Ensure columns in SELECT are either in GROUP BY or inside aggregates</li>
</ol>
<p>The full implementation handles these cases but the code is involved. See the source repository for details.</p>
<h2 id="why-build-your-own-parser"><a class="header" href="#why-build-your-own-parser">Why Build Your Own Parser?</a></h2>
<p>You might wonder why we build a parser instead of using a parser generator like ANTLR or a library like Apache Calcite.</p>
<p>Building a hand-written parser has advantages:</p>
<ul>
<li>Control: You decide exactly what SQL features to support</li>
<li>Error messages: You can produce clear, context-specific errors</li>
<li>Simplicity: No external dependencies or generated code</li>
<li>Learning: Understanding parsing deepens your understanding of the whole system</li>
</ul>
<p>For a production system, using an existing SQL parser is often sensible. But for learning how query engines work, building a parser reveals how SQL’s apparent flexibility maps to structured operations.</p>
<p><em>This book is also available for purchase in ePub, MOBI, and PDF format from <a href="https://leanpub.com/how-query-engines-work">https://leanpub.com/how-query-engines-work</a></em></p>
<p><strong>Copyright © 2020-2025 Andy Grove. All rights reserved.</strong></p>

                        
</body>
</html>