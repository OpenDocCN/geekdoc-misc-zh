- en: Benchmarks
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基准测试
- en: 原文：[https://howqueryengineswork.com/17-benchmarks.html](https://howqueryengineswork.com/17-benchmarks.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://howqueryengineswork.com/17-benchmarks.html](https://howqueryengineswork.com/17-benchmarks.html)
- en: Each query engine is unique in terms of performance, scalability, and resource
    requirements, often with different trade-offs. Benchmarks help us understand these
    characteristics and make informed decisions about which query engine to use for
    a particular workload. They also help query engine developers identify performance
    regressions and track improvements over time.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 每个查询引擎在性能、可扩展性和资源需求方面都是独特的，通常会有不同的权衡。基准测试帮助我们了解这些特性，并就针对特定工作负载使用哪个查询引擎做出明智的决定。它们还有助于查询引擎开发者识别性能退化并跟踪改进。
- en: '[Measuring Performance](#measuring-performance)'
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[测量性能](#measuring-performance)'
- en: Performance is often the simplest characteristic to measure and usually refers
    to the time it takes to perform a particular operation. For example, benchmarks
    can be built to measure the performance of specific queries or categories of query.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 性能通常是衡量最简单的特性，通常指的是执行特定操作所需的时间。例如，可以构建基准测试来衡量特定查询或查询类别的性能。
- en: Performance tests typically involve executing a query multiple times and measuring
    elapsed time.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 性能测试通常涉及多次执行查询并测量经过的时间。
- en: '[Measuring Scalability](#measuring-scalability)'
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[测量可扩展性](#measuring-scalability)'
- en: Scalability can be an overloaded term and there are many different types of
    scalability. The term scalability generally refers to how performance varies with
    different values for some variable that affects performance.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 可扩展性是一个多义词，有各种不同的类型。术语可扩展性通常指的是性能如何随着影响性能的一些变量的不同值而变化。
- en: One example would be measuring scalability as total data size increases to discover
    how performance is impacted, when querying 10 GB of data versus 100 GB or 1 TB.
    A common goal is to demonstrate linear scalability, meaning that querying 100
    GB of data should take 10 times as long as querying 10 GB of data. Linear scalability
    makes it easy for users to reason about expected behavior.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 一个例子是测量可扩展性，随着总数据量的增加来发现性能是如何受到影响的，例如查询10GB数据与100GB或1TB数据时的性能。一个常见的目标是展示线性可扩展性，这意味着查询100GB数据应该比查询10GB数据花费10倍的时间。线性可扩展性使用户能够轻松地推理预期行为。
- en: 'Other examples of variables that affect performance are:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 影响性能的其他变量示例包括：
- en: Number of concurrent users, requests, or queries.
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 并发用户、请求或查询数量。
- en: Number of data partitions.
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据分区数量。
- en: Number of physical disks.
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 物理磁盘数量。
- en: Number of cores.
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 核心数量。
- en: Number of nodes.
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 节点数量。
- en: Amount of RAM available.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可用RAM量。
- en: Type of hardware (Raspberry Pi versus Desktop, for example).
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 硬件类型（例如，树莓派与台式机）。
- en: '[Concurrency](#concurrency)'
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[并发性](#concurrency)'
- en: When measuring scalability based on number of concurrent requests, we are often
    more interested in throughput (total number of queries executed per period of
    time) rather than the duration of individual queries, although we typically would
    collect that information as well.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 当基于并发请求数量测量可扩展性时，我们通常更感兴趣的是吞吐量（在特定时间段内执行的查询总数）而不是单个查询的持续时间，尽管我们通常也会收集这些信息。
- en: '[Automation](#automation)'
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[自动化](#automation)'
- en: Benchmarks are often very time-consuming to run and automation is essential
    so that the benchmarks can be run often, perhaps once per day or once per week,
    so that any performance regressions can be caught early.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 基准测试通常运行时间较长，自动化是必不可少的，以便经常运行基准测试，可能每天或每周运行一次，以便能够尽早发现性能退化。
- en: Automation is also important for ensuring that benchmarks are executed consistently
    and that results are collected with all relevant details that might be needed
    when analyzing the results.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 自动化对于确保基准测试的一致执行和收集分析结果时可能需要的所有相关细节也是非常重要的。
- en: 'Here are some examples of the type of data that should be collected when executing
    benchmarks:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在执行基准测试时，以下是一些应该收集的数据类型示例：
- en: '[Hardware Configuration](#hardware-configuration)'
  id: totrans-23
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[硬件配置](#hardware-configuration)'
- en: Type of hardware
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 硬件类型
- en: Number of CPU cores
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CPU核心数量
- en: Available memory and disk space
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可用内存和磁盘空间
- en: Operating system name and version
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 操作系统名称和版本
- en: '[Environment](#environment)'
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[环境](#environment)'
- en: Environment variables (being careful not to leak secrets)
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 环境变量（注意不要泄露机密信息）
- en: '[Benchmark Configuration](#benchmark-configuration)'
  id: totrans-30
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[基准配置](#benchmark-configuration)'
- en: Version of benchmark software used
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用的基准软件版本
- en: Version of software under test
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测试软件的版本
- en: Any configuration parameters or files
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 任何配置参数或文件
- en: Filenames of any data files being queried
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 被查询的任何数据文件的文件名
- en: Data sizes and checksums for the data files
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据文件的数据大小和校验和
- en: Details about the query that was executed
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行的查询的详细信息
- en: '[Benchmark Results](#benchmark-results)'
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[基准测试结果](#benchmark-results)'
- en: Date/time benchmark was started
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基准测试开始的时间/日期
- en: Start time and end time for each query
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个查询的开始时间和结束时间
- en: Error information for any failed queries
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 任何失败查询的错误信息
- en: '[Comparing Benchmarks](#comparing-benchmarks)'
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[比较基准测试](#comparing-benchmarks)'
- en: It is important to compare benchmarks between releases of the software so that
    changes in performance characteristics are apparent and can be investigated further.
    Benchmarks produce a lot of data that is often hard to compare manually, so it
    can be beneficial to build tooling to help with this process.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 比较软件发布之间的基准测试非常重要，这样就可以清楚地看到性能特性的变化，并可以进行进一步的研究。基准测试产生大量数据，通常难以手动比较，因此构建帮助这一过程的工具可能是有益的。
- en: Rather than comparing two sets of performance data directly, tooling can perform
    a “diff” of the data and show percentage differences between two or more runs
    of the same benchmark. It is also useful to be able to produce charts showing
    multiple benchmark runs.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 与直接比较两组性能数据相比，工具可以对数据进行“diff”操作，并显示同一基准测试两次或多次运行之间的百分比差异。能够生成显示多次基准测试运行的图表也非常有用。
- en: '[Visualising Benchmark Results](#visualising-benchmark-results)'
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[可视化基准测试结果](#visualising-benchmark-results)'
- en: Raw benchmark data in tabular form can be difficult to interpret. Charts and
    graphs make it much easier to see patterns, identify anomalies, and communicate
    results to others.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 以表格形式呈现的原始基准测试数据可能难以解释。图表和图形可以使看到模式、识别异常以及向他人传达结果变得容易得多。
- en: When visualising performance data, consider charting throughput rather than
    raw execution times. Throughput, often expressed as queries per minute or queries
    per second, provides a more intuitive measure of system capacity. If a query takes
    5 seconds to execute, then the system can handle 12 queries per minute on a single
    thread. This framing makes it easier to understand real-world capacity.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在可视化性能数据时，考虑绘制吞吐量而不是原始执行时间。吞吐量，通常以每分钟或每秒查询数表示，提供了衡量系统容量的更直观的度量。如果一个查询需要5秒钟来执行，那么在单个线程上，系统可以处理每分钟12个查询。这种框架使得理解现实世界的容量变得更容易。
- en: Line charts work well for showing how performance scales with increasing resources
    such as CPU cores or memory, or with increasing data sizes. Bar charts are useful
    for comparing different configurations or different query engines side by side.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 折线图非常适合显示性能如何随着CPU核心或内存等资源的增加而扩展，或者随着数据大小的增加而扩展。条形图用于并排比较不同的配置或不同的查询引擎。
- en: Be careful when creating visualisations to use appropriate scales. Starting
    a y-axis at zero rather than at some arbitrary value gives a more honest representation
    of differences between data points. Using logarithmic scales can be appropriate
    when dealing with data that spans several orders of magnitude.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建可视化时，请小心使用适当的刻度。将y轴从零开始而不是从某个任意值开始，可以更真实地表示数据点之间的差异。在处理跨越几个数量级的数值数据时，使用对数刻度可能是合适的。
- en: '[Transaction Processing Council (TPC) Benchmarks](#transaction-processing-council-tpc-benchmarks)'
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[事务处理委员会（TPC）基准测试](#transaction-processing-council-tpc-benchmarks)'
- en: The Transaction Processing Council is a consortium of database vendors that
    collaborate on creating and maintaining various database benchmark suites to allow
    for fair comparisons between vendor’s systems. Current TPC member companies include
    Microsoft, Oracle, IBM, Hewlett Packard Enterprise, AMD, Intel, and NVIDIA.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 事务处理委员会是一个数据库供应商的联盟，它们合作创建和维护各种数据库基准测试套件，以便在供应商的系统之间进行公平的比较。当前的TPC成员公司包括微软、甲骨文、IBM、惠普企业、AMD、英特尔和英伟达。
- en: The first benchmark, TPC-A, was published in 1989 and other benchmarks have
    been created since then. TPC-C is a well known OLTP benchmark used when comparing
    traditional RDBMS databases, and TPC-H (discontinued) and TPC-DS are often used
    for measuring performance of “Big Data” query engines.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个基准测试，TPC-A，于1989年发布，此后还创建了其他基准测试。TPC-C是一个著名的OLTP基准测试，用于比较传统的RDBMS数据库，而TPC-H（已停用）和TPC-DS通常用于衡量“大数据”查询引擎的性能。
- en: TPC benchmarks are seen as the “gold standard” in the industry and are complex
    and time consuming to implement fully. Also, results for these benchmarks can
    only be published by TPC members and only after the benchmarks have been audited
    by the TPC. Taking TPC-DS as an example, the only companies to have ever published
    official results at the time of writing are Alibaba.com, H2C, SuperMicro, and
    Databricks.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: TPC基准被看作是行业中的“黄金标准”，但完全实施起来既复杂又耗时。此外，这些基准的结果只能由TPC成员发布，并且只有在基准经过TPC审计之后才能发布。以TPC-DS为例，截至写作时，唯一发布过官方结果的只有阿里巴巴、H2C、SuperMicro和Databricks。
- en: However, the TPC has a Fair Use policy that allows non-members to create unofficial
    benchmarks based on TPC benchmarks, as long as certain conditions are followed,
    such as prefixing any use of the term TPC with “derived from TPC”. For example,
    “Performance of Query derived from TPC-DS Query 14”. TPC Copyright Notice and
    License Agreements must also be maintained. There are also limitations on the
    types of metrics that can be published.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，TPC有一个公平使用政策，允许非成员根据TPC基准创建非官方基准，只要遵循某些条件，例如在提及TPC时加上“源自TPC”的前缀。例如，“源自TPC-DS查询14的查询性能”。还必须维护TPC版权声明和许可协议。对可以发布的指标类型也有限制。
- en: Many open source projects simply measure the time to execute individual queries
    from the TPC benchmark suites and use this as a way to track performance over
    time and for comparison with other query engines.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 许多开源项目只是测量TPC基准套件中单个查询的执行时间，并将其作为跟踪性能随时间变化以及与其他查询引擎进行比较的一种方式。
- en: '[Common Pitfalls](#common-pitfalls)'
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[常见错误](#common-pitfalls)'
- en: There are several common mistakes to avoid when designing and running benchmarks.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在设计和运行基准测试时，有一些常见的错误需要避免。
- en: The first run of a query is often slower than subsequent runs due to JIT compilation,
    cache population, and other startup effects. Running several warm-up iterations
    before collecting measurements helps ensure that results reflect steady-state
    performance rather than cold-start behaviour.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 查询的第一次运行通常比后续运行慢，这是由于即时编译、缓存填充和其他启动效应造成的。在收集测量数据之前运行几个预热迭代可以帮助确保结果反映稳态性能而不是冷启动行为。
- en: Running benchmarks on a machine that is also doing other work can introduce
    significant variability. Dedicated benchmark environments, or at least ensuring
    minimal background activity, produce more reliable results.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在同时进行其他工作的机器上运行基准测试可能会引入显著的可变性。专用基准环境，或者至少确保最小化背景活动，可以产生更可靠的结果。
- en: Running a query once and reporting that single result tells you very little.
    Running multiple iterations and reporting statistics such as mean, median, and
    standard deviation gives a much better picture of typical performance and its
    variability.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 只运行一次查询并报告该结果告诉你很少。运行多次迭代并报告统计数据，如平均值、中位数和标准差，可以更全面地了解典型性能及其可变性。
- en: Benchmarks that use tiny datasets or trivially simple queries may not reveal
    performance characteristics that matter for real workloads. Using realistic data
    sizes and query complexity is important for meaningful results.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 使用小型数据集或极其简单的查询的基准测试可能无法揭示对实际工作负载重要的性能特征。使用真实的数据大小和查询复杂度对于获得有意义的成果至关重要。
- en: It can be tempting to only show results that make your query engine look good,
    but publishing complete results, including queries where performance is poor,
    builds credibility and helps identify areas for improvement.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 只展示使你的查询引擎看起来好的结果可能很有吸引力，但发布完整的结果，包括性能较差的查询，可以建立信誉并帮助识别改进领域。
- en: '[Building Your Own Benchmarks](#building-your-own-benchmarks)'
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[构建自己的基准](#building-your-own-benchmarks)'
- en: While industry-standard benchmarks like TPC-DS are valuable for comparing different
    systems, they may not reflect your specific workload. Building custom benchmarks
    based on real queries from your application can provide more relevant insights.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然行业标准基准如TPC-DS对于比较不同的系统很有价值，但它们可能无法反映你的特定工作负载。基于你的应用程序中的真实查询构建自定义基准可以提供更相关的见解。
- en: When building custom benchmarks, start by identifying the queries that matter
    most to your users. These might be the most frequently executed queries, or the
    queries that are most sensitive to latency. Instrument your application to collect
    query logs, then select representative queries for benchmarking.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建自定义基准时，首先确定对用户最重要的查询。这些可能是执行最频繁的查询，或者是对延迟最敏感的查询。对你的应用程序进行仪器化以收集查询日志，然后选择代表性的查询进行基准测试。
- en: Create datasets that match your production data in terms of size, distribution,
    and schema complexity. Synthetic data generators can help create large datasets
    with controlled characteristics, but be aware that randomly generated data may
    have different statistical properties than real data.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 创建与生产数据在大小、分布和模式复杂性方面相匹配的数据集。合成数据生成器可以帮助创建具有可控特性的大型数据集，但请注意，随机生成的数据可能具有与真实数据不同的统计特性。
- en: Document your benchmark methodology thoroughly so that results can be reproduced.
    This includes not just the queries and data, but also the hardware, operating
    system, and any configuration settings that might affect performance.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 详细记录你的基准测试方法，以便结果可以重现。这包括不仅限于查询和数据，还包括硬件、操作系统以及可能影响性能的任何配置设置。
- en: '*This book is also available for purchase in ePub, MOBI, and PDF format from
    [https://leanpub.com/how-query-engines-work](https://leanpub.com/how-query-engines-work)*'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '*本书也以ePub、MOBI和PDF格式从[https://leanpub.com/how-query-engines-work](https://leanpub.com/how-query-engines-work)购买*。'
- en: '**Copyright © 2020-2025 Andy Grove. All rights reserved.**'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '**版权所有 © 2020-2025 安迪·格鲁夫。保留所有权利**。'
