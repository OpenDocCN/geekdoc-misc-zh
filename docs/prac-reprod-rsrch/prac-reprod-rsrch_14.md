# 开发和分析量子多体系统的精确对角化模拟，并从结果中创建一个富含来源信息的出版物

# 将量子多体系统的模拟转化为一个富含来源信息的出版物

## Jan Gukelberger 和 Matthias Troyer

我的名字是 Jan Gukelberger，我是一名计算凝聚态物理学家，最近在苏黎世联邦理工学院理论物理研究所完成了博士学位。这个案例研究描述了我作为博士生的第一年（2010-2011）参与的一个项目。这个案例研究是与我的导师 Matthias Troyer 一起进行的。

广义上说，该项目的目标是表征一类量子多体模型系统。一个特定的模型由一个大矩阵，即哈密顿量，描述，其物理性质可以从最低能量本征值（能量）和相应的本征矢量（量子态）中推导出来。因此，我编写了一个 C++程序，用于为给定的模型参数集构建哈密顿矩阵，运行迭代对角化算法，并输出相应的性质。对该程序产生的不同参数的结果进行分析，可以更深入地理解所研究的模型系列，并证实同事获得的分析结果。最终，分析和数值结果一起发表在[Phys. Rev. B 85, 045414 (2012)](http://dx.doi.org/10.1103/PhysRevB.85.045414)中。

### 工作流程

![图表](img/jgukelberger.png) 由于模拟可能需要大量的计算资源（在集群或大型工作站上），重新一次性运行整个过程通常是不可行或不可取的。因此，我们通常采用两步方法：模拟运行的输出被视为主要/原始数据，与包含源代码版本、执行环境和输入参数详细信息的日志文件一起存档。将这些原始数据评估和转换为最终结果（通常是带有图表的图）应尽可能容易地重复，最好只需按一下按钮或执行脚本即可。

在这项研究中，我们选择将原始数据作为补充信息发布在出版商（APS）的网站上，并为[VisTrails](http://www.vistrails.org)系统提供工作流文件，该系统可以从服务器检索原始数据并重新创建论文中包含的图表。VisTrails 是一个开源的科学工作流和来源管理系统，用于项目中的数据评估和绘图任务。这样，任何读者都可以详细检查并重新运行我们数据分析的所有步骤。

项目开始时是用 C++开发模拟代码。一旦代码准备好，就会用它来探索正在研究的物理模型的特性。为此，它在不同的系统（工作站和集群）上使用不同的输入参数编译和运行。由于模拟代码在研究过程中不断调整和扩展，因此记录哪个版本的代码产生了哪些结果至关重要。为此，我们使用一个运行脚本（Python），记录代码版本（子版本修订）、运行的输入参数，以及有关构建配置（编译器、库等）和运行代码的系统环境的详细信息（主机、日期和时间、动态库等）。所有这些细节都写入到与包含模拟结果的数据文件相邻的日志文件中。它们通过具有相同的文件名（直到扩展名为止，.dat 和.log）在语义上相互关联。

这些输出文件构成了原始数据，这些数据在桌面系统上收集以进行评估。评估通常从几个模拟中加载数据文件（对应不同的输入参数），计算数据的一些数值转换，最后生成一个或多个图形（PDF 文件）与数据图。我们在 VisTrails 工作流中编码评估过程，利用[ALPS](http://alps.comp-phys.org)包（与 VisTrails 一起提供），其中包含许多用于常见过程的实用程序例程，如数据转换、拟合和绘图。我们通常希望每个图形有一个单独的工作流程（VT 文件）。这增加了模块化，并使工作流的开发更容易，但意味着如果要重新创建所有图形，则需要打开并执行几个 VT 文件。

最后，论文的手稿是用 LaTeX 编写的，包括由 VT 工作流创建的图形文件。 LaTeX 编译生成 PDF 文件，这构成了出版物的核心部分。

与原始数据和工作流一起发布论文，使读者能够轻松检查和重现我们的数据评估过程，结果成为一个挑战，并且需要与出版商进行密切交流。在这里，主要问题是手稿、VT 工作流和原始数据之间需要跨引用，因为每个组件的最终位置只有在生产过程的最后一步才能获得，当文件不能再在没有生产团队的手动干预的情况下更改时。这个问题的一些方面在我们的报告[发表丰富来源的科学论文，Procs. TAPP'11](https://www.usenix.org/event/tapp11/tech/final_files/Bauer.pdf)中有详细解释。最终，出版商无法在论文中的图表与相应的工作流文件之间插入链接，而只能在其服务器上的补充材料部分中提供对补充材料的一般引用，其中包括所有的工作流文件可供下载。

注意：实际上，有一个合作者在发表之前使用了不同的绘图工具重新创建了图表，以改善它们的视觉效果。为此，我们修改了 VT 工作流，在绘图之前将预处理数据导出到外部文件。因此，论文中呈现的图表是等效的，但不完全相同于 VT 工作流创建的图表。

### 痛点

除了复杂的出版流程之外，研究过程中的主要痛点与数据评估必须在 VisTrails GUI 中完成以及 VisTrails 工作流文件格式不透明有关：

+   数据评估（执行 VT 工作流）当时无法进行脚本化。

+   评估无法在集群/通过 ssh 上运行。

+   版本管理变得更加困难，因为查看版本之间的差异不像查看 Python 脚本的 diff 文件那样容易。

+   这也使得在不同机器之间（例如笔记本电脑和工作站）同步工作流变得不那么简单。

当在 APS 服务器上检查“可重现的出版物”时，发表后三年，一些中长期问题变得明显，因为所使用的软件和出版商的基础设施都在发展。需要持续测试和维护发布的说明和工作流，以跟上变化：

+   伴随文章的补充材料部分中提供的指令不能直接在当前 VisTrails 版本下使用：在撰写时最新稳定的 VisTrails 发布版本（2.2）中，ALPS 软件包损坏，并且需要使用最新（尚未发布）的 ALPS 版本进行修补。否则，ALPS 软件包的初始化将失败，工作流无法执行。

+   APS 期刊无法保证补充材料的长期稳定位置。事实上，URL 已经更改，因此工作流无法从 APS 服务器获取原始数据，除非在每个工作流中手动修复 URL。举一个具体例子，原始位置 [`prb.aps.org/epaps/PRB/v85/i4/e045414/dyl_ladder_gap.zip`](http://prb.aps.org/epaps/PRB/v85/i4/e045414/dyl_ladder_gap.zip) 已更改为 [`journals.aps.org/prb/supplemental/10.1103/PhysRevB.85.045414/dyl_ladder_gap.zip`](http://journals.aps.org/prb/supplemental/10.1103/PhysRevB.85.045414/dyl_ladder_gap.zip)。此外，错误的原因对于未经培训的人来说并不容易修复，因为 DownloadFile 模块实际上成功了（它下载了显示在旧 URL 上的 html 文件），但随后的 UnzipDirectory 模块失败，并显示“BadZipFile: File is not a zip file”消息。因此，我们，作者，需要准备新的工作流，使用适应的 URL，并在出版商的基础设施更改时发送给他们以替���原始的工作流。

基于这些原因，我现在更倾向于发布一个自包含的存档，其中包含原始数据和一个具有最小依赖关系的脚本，使用广泛使用的语言，如 Python，重新运行分析并重现图表。这样更加稳健，可以应对出版商基础设施的变化。此外，与专用解决方案如 VisTrails/ALPS 相比（无论软件开发人员目前多么专业和乐于助人），脚本在广泛使用的语言中的向后兼容性问题可能更容易解决。

### 关键优势

最重要的一点是记录使用何种输入参数运行了哪个版本的模拟代码。这可以排除一些“不可重现结果”的最糟糕情况，并且绝对应该成为标准做法。（我无法判断在我们领域中这种做法有多普遍，因为代码和日志文件很少被发布。）

第二点是实际发布原始数据和评估工作流程，使任何读者都可以直接检查评估过程的所有细节，甚至是作者认为不重要（或忘记）在论文中提及的细节。在我们领域，这显然不是普遍做法，但在我看来这是非常可取的。

### 问题

#### 对于你来说，“可重现性”是什么意思？

总的来说，鉴于一篇出版物（在同行评议的期刊中），源代码和原始数据（可能公开可用或在机构的存储库中），我领域的专家应该能够理解，并原则上重复研究的每一步，从运行正确版本的模拟代码到发表论文中呈现的最终结果。

#### 你是如何或从何处了解到可重现性的？

一些基本原则是相当明显的，但将它们整合到高效的工作流程中可能需要一些编程/版本控制经验。我接触到 VisTrails 软件是因为我们团队与 VisTrails 开发人员之间的合作，旨在将 ALPS 软件包的评估工具（在我们团队内开发）与 VisTrails 集成。

#### 您认为在您领域进行可重复研究的主要挑战是什么，您有什么建议？

主要挑战可能是尽可能简化溯源数据的记录，以便没有人有借口不这样做。

另一个问题是，模拟代码、原始数据和评估工具很少被公开发布。大多数研究人员非常不愿意公开他们的代码，例如因为他们不希望竞争对手在他们之前使用他们的代码发布结果，或者因为他们对自己的代码质量感到羞愧。原始数据可能很大且格式非标准化。评估可能由一系列不同的工具执行，这使得工作流程的发布变得困难。

#### 您认为进行可重复研究的主要动机是什么？

除了研究伦理和机构要求要求这样做外，记录溯源信息可以使研究人员在发现单个研究中或不同研究人员进行的研究中产生不同结果时，生活变得更加轻松。（差异是由代码的不同、不同的输入参数还是数据评估引起的？）
