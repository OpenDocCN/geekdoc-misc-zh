# 基本可重复工作流程模板

# 基本可重复工作流程模板

## Justin Kitzes

本书的核心是一组三十一个案例研究，每个案例研究都展示了一个科学工作流程的例子，该工作流程至少在某种程度上是为了实现可重复性而设计的目标。这些案例研究主要涉及计算可重复性的目标，即第二个研究者能够接收一组文件，包括数据、代码和文档，并重新创建或恢复研究项目的输出，包括图表和其他关键的定量和定性结果。

本卷中的三十一个案例研究描述了各种各样的研究项目、学科、方法和工具。然而，在这种多样性背后，所有案例研究都有许多共同的关键原则和实践。在本章中，我们描述了我们认为是任何科学家在继续阅读案例研究章节中描述的复杂性之前应该掌握的基本、潜在的可重复研究工作流程。

为了展示这个基本工作流程，本章通过一个完整的、具体的例子走过了一个可能是最简单的现实数据密集型研究项目：对单个表格数据集进行回归分析。这个例子旨在为理解本书后面描述的案例研究提供有用的背景。它还将为寻找适应自己研究需求的模板的初学者提供一个独立的可重复研究实践介绍。我们特别鼓励初学者与本章中的示例互动工作，以了解可重复工作流程如何实现。

我们从介绍使任何研究项目，无论多么简单，都能计算上可重复所需的三个关键实践开始本章。接下来是基本可重复研究工作流程的高层次概述。然后，我们提供了如何在一个简单的研究项目中实现这个工作流程的扩展示例。最后，我们总结了从这个简单工作流程模板转换到更复杂工作流程时涉及的一些额外考虑因素，比如那些在案例研究章节中描述的。

### 三个关键实践

第二章描述了一组问题，可用于相对细粒度地评估研究项目的可重复性程度。在更高的层次上，我们可以总结这些建议为三个通用实践，这些实践在研究项目的所有阶段都反复出现：

1.  清晰地分离、标记和记录所有数据、文件和对数据和文件的操作

1.  完全记录所有操作，尽可能自动化，并在可行时避免手动干预工作流程

1.  将工作流程设计为一系列小步骤的序列，这些步骤通过一个步骤的中间输出作为下一个步骤的输入而粘合在一起。

在初级阶段，第一项实践主要涉及将文件放置在清晰的目录结构中，并创建元数据来描述它们。第二项实践是通过编写代码或脚本来自动执行每个步骤，或者在不可能的情况下，记录完成任务所需的所有手动步骤，以便第二个研究人员可以明确地重复它们。第三项实践是通过整体工作流程设计来实现，特别是清晰地概念化需要按顺序发生的不同操作以及它们如何相互支持。

尽管下面的示例中没有描述，但本书中大多数贡献的案例研究都使用版本控制软件作为遵循上述前两项实践的工具。简而言之，版本控制用于在任何时刻捕获项目所有文件的快照，使研究人员能够轻松地查看项目的历史并管理未来的更改。版本控制还提供了一种系统和透明地记录和跟踪项目文件更改的方法。

然而，根据我们的经验，许多初学者发现版本控制比下面描述的其他步骤更难学习，因此我们选择不在此基本工作流程模板中包含它。然而，一旦您对这个基本工作流程感到舒适，我们建议您进一步学习使用版本控制系统的许多在线教程之一。我们特别推荐软件工坊提供的关于`git`的教程。

### 基本可重现工作流程的阶段

基本可重现研究工作流程可以分为三个主要阶段：数据获取、数据处理和数据分析。这三个阶段之前的活动涉及系统设置，之后的步骤尽可能自动化整个工作流程。虽然项目头脑风暴和出版等步骤也可能是研究工作流程的关键部分，但与确保项目可重现性相关的任务主要在这些阶段内。

在开始数据密集型计算研究项目之前，必须找到并设置具有完成分析所需工具的计算机系统。这些活动可能更多或更少地涉及，主要取决于研究人员对计算机的访问级别以及将用于分析的编程语言。

基本工作流的第一个阶段是数据获取、输入或创建。这个阶段通常包括从主要来源收集数据，比如野外观察、实验研究或调查。然而，它也可能包括通过网络抓取或与其他研究人员交流获取现有来源的数据，或通过模拟生成数据。无论采用何种方法，这个第一阶段的最终结果都是原始数据。

第二阶段涉及对第一阶段产生的数据进行处理或清洗。根据所使用的工具和作者的策略，这个阶段可能包括手动数据输入、视觉数据审查，或使用脚本或其他软件进行系统数据操作或过滤等任务。在完成第二阶段后，相关数据被数字化、清洗，并完全准备好进行分析。尽管这个阶段通常被视为次要的，或者比其周围的其他两个阶段不那么重要，但我们发现，这个阶段通常需要与其他阶段一样多的智力能量和同样多的困难决策。

第三阶段是数据分析。数据分析最常见的形式是形式统计，但该阶段的其他活动还包括数据可视化、评估特定算法的性能，并扩展数据以解决假设或得出科学结论。该阶段的定义属性是以某种方式分析第二阶段产生的干净数据，并生成所需的科学研究产品，通常是数量化结果，以图表的形式呈现在手稿、演讲和其他形式的交流中。

最后，在三个核心阶段之后，通过创建一个可以自动执行所有三个阶段以生成最终结果的单个控制脚本，可以极大地增强项目的可重现性。当由于项目约束而无法实现或不切实际的"一键式"工作流时，应创建所有非自动化步骤的详细文档。

### 设置

在可重现工作流的三个核心阶段之前，设置活动首先包括获取计算机或多台计算机以用于项目。对于这个简单的示例，我们假设整个分析将在一台研究人员具有完全管理员权限的个人计算机上进行。

通常在此阶段必须安装三类工具。其中之一是允许访问命令行的 shell 或终端程序。第二个是纯文本编辑器或可用于以选择的语言编写代码的开发环境。第三个是允许用户在选择的编程语言中编写和执行代码的软件。或者，研究人员可以选择使用集成的工作流程程序，例如[VisTrails](http://www.vistrails.org)，[Taverna](https://taverna.incubator.apache.org/)或[Kepler](https://kepler-project.org/)，尽管这种方法在此不讨论。

对于随后的基本工作流程，Mac 或 Linux 用户可以使用其系统上预安装的 Terminal 程序，而 Windows 用户可以在命令提示符下工作。所有用户都应安装一个纯文本编辑器，每个平台都有许多可用。最后，下面的示例将使用 R 语言，并且用户应下载并安装最新版本的[R](https://www.r-project.org/)。

有关上述安装步骤的更详细信息，以及如何使用这些工具的基本教程，请参阅[软件 Carpentry 课程](http://software-carpentry.org/lessons/)。

### 阶段 1：数据采集

大多数数据密集型工作流程的第一阶段涉及原始数据的获取。在本例中，我们将想象进行了一项研究，我们在其中收集了关于作为农业实验的一部分种植的番茄的田间数据。

表 1 报告了三个田地中每个田地四株植物的总产量的假设测量结果，单位为每株植物的千克，种植后不进行管理（N），常规管理，包括肥料和杀虫剂（C），或有机管理（O）。第三列指示是否在收获时注意到植物叶子上有大量昆虫损害。在标记为`NA`的质量列中，15 株植物中有两株在结果之前被杀死。

表 1：样本番茄数据集

| 字段 | 重量 | 昆虫 |
| --- | --- | --- |
| N | 5.8 | Y |
| N | 5.9 | N |
| N | 1.6 | Y |
| N | 4.0 | Y |
| N | 2.9 | Y |
| C | 12.4 | N |
| C | 11.5 | N |
| C | 9.3 | N |
| C | NA | N |
| C | 12.1 | N |
| O | 9.9 | N |
| O | 6.7 | N |
| O | 10.6 | Y |
| O | 3.7 | Y |
| O | NA | N |

这些数据应输入电子表格程序并保存为 CSV 文件。CSV 文件是一种常用的纯文本格式，用于存储表格数据，其中表的每一行都在单独的一行上，每列的数据由逗号分隔。纯文本格式通常优于特定于程序的格式，例如 XLSX，因为它们更容易被各种软件和其他可能希望使用此数据的研究人员阅读。

创建此文件后，应给它一个名称并保存在一个有用的位置。命名约定在研究人员之间差异很大，但在像这样的小项目中，我们建议使用能够有用地描述文件内容的名称，即使这些名称有些冗长。例如，这个表格可能被保存为`raw_yield_data.csv`。为了避免后续工作流程中出现错误的可能性，文件名不应使用空格、句点和斜杠。

数据保存的同时，还应创建并保存一个元数据文件。元数据文件的目的是记录数据的来源和任何相关信息。虽然许多学科都有元数据标准，但最小的元数据文件由一个简单的文本文件组成，以纯英语描述数据的来源和描述。这样一个文件，我们可以将其保存在与数据文件相邻的`README.txt`中，可能包含如下信息。

> 约翰·史密斯教授在伯克利野外站的本科助理收集的数据。所有植物均位于第 3 田地，并在约 12 英寸高时选择进行测量。产量记录于 2015 年 8 月。
> 
> 田间代码表示无处理（N）、传统（C）和有机（O）。产量以千克为单位，NA 表示在产量测量前死亡的植物。通过目测评估昆虫损伤，Y 表示叶面积损失超过 25%。

随之而来的问题是这两个文件，以及将成为项目一部分的所有后续文件应该保存在哪里。一种常见的惯例是将所有项目文件放在单个目录中，其中包括不同类型文件的一个子目录，如数据、源代码、分析结果等。像下面这样的结构，所有文件和子文件夹都包含在一个名为`tomato_project`的单个文件夹中，为简单项目提供了一个有用的起点。

```
|-- tomato_project
|   |-- data_raw
|   |   |-- raw_yield_data.csv
|   |   |-- README.txt
|   |-- data_clean
|   |-- results
|   |-- src 
```

### 第二阶段：数据处理

一旦收集到原始数据并放置在项目目录中，几乎总是需要对其进行某种形式的处理或清理，以便在分析中使用。此步骤可能涉及删除无效数据、子集原始数据、删除异常值和其他类似的步骤。处理原始数据集的最佳方法当然取决于研究人员希望用这些数据回答的问题以及计划用于第三阶段的特定类型的分析。

在这个例子中，检查原始数据表格发现两株未进行产量测量的植物，我们可能希望在进一步分析之前从数据中删除这些植物。考虑到最终进行传统和有机产量比较的两样本 t 检验的目标，我们也知道可以在这个阶段从表格中删除无处理的植物。对于像这样的小表格，删除这些行并不是绝对必要的，尽管这样的子集操作可以提高对更大数据集的后续分析的效率。

要使这个阶段完全可重现，必须记录处理数据的每一步骤，细节足够精细，以至于只有一个处理后数据集可以从原始数据和一系列指令的组合中产生。实现这一点的最简单和推荐的方法是将数据处理的指令编码为计算机代码，即在一个脚本中，读取原始数据，执行各种处理和清洗操作，并将生成的处理后数据保存为新文件。

对于小型表格数据，可能会诱人地跳过这个编码步骤，而是在图形编辑器中打开文件，如电子表格程序，删除不需要的行或列，并保存生成的文件。在某些情况下，特别是数据文件存储在只能被某些程序打开的专有格式中时，这种手动方法可能是唯一的选择。然而，手动数据处理容易出错，并使后面描述的“一键式”自动化工作流程变得不可能。

与所有研究任务一样，如果这一步必须手动完成，请确保处理后的数据文件附有非常详细的人类可读描述，保存在类似元数据文件的文本文件中，描述对原始数据执行的每个操作，直到选择了哪个菜单并按照什么顺序点击了哪个按钮。请记住，如果一个你从未见过的人无法准确地、100%地从原始数据和指令中重现处理后的数据文件，那么这一步就不是完全可重现的。在许多方面，这个指令文件本身类似于代码，尽管它是为人类读者而不是计算机执行的。

对于这个番茄产量数据，我们可以轻松地编写一个简短的脚本，读取原始表格，删除具有`NA`产量和字段代码为`N`的行，并保存生成的处理后数据。以下的 R 命令将执行这些操作。

```
yield_data <- read.csv("yield_data.csv")
clean_yield_data <- na.omit(raw_yield_data[raw_yield_data$Field != "N", ])
write.csv(clean_yield_data, "clean_yield_data.csv") 
```

在探索数据时，上述命令可以交互式地输入到解释器窗口中。然而，一旦确定了数据处理的程序，所有这些命令都应该放在一个单独的文件中，当执行时，将读取原始数据，处理它，并保存生成的处理后数据文件。这确保了所有必要的步骤都被正确记录下来，并且可以轻松地随意重复。

在前面描述的简单目录结构中，脚本和其他代码保存在`src`子文件夹中。为了确保`src`目录中的脚本能够定位并保存适当的文件到适当的文件夹中，我们可以修改上面的代码如下，修改文件读取和写入的位置。请注意，我们还添加了描述每行代码意图的注释。

```
### Read in the raw data, assuming we are working in the src directory
raw_yield_data <- read.csv("../data_raw/raw_yield_data.csv")

### Clean the data by removing rows with NA and where 'Field' == N
clean_yield_data <- na.omit(raw_yield_data[raw_yield_data$Field != "N", ])

### Write the clean data to disk
write.csv(clean_yield_data, "../data_clean/clean_yield_data.csv") 
```

上述命令保存为 `clean_data.R` 脚本后，放在 `src` 子文件夹中，将从 `data_raw` 子文件夹中读取表格 `raw_yield_data.csv`，对其进行清理，并将清理后的结果保存为 `clean_yield_data.csv`，放在 `data_clean` 子文件夹中。清理后的数据被放置在不同的子文件夹中，以确保原始的、未经处理的数据不会与任何派生的数据产品混淆。理想情况下，不应更改原始数据文件，所有的更改和修改都应保存在单独的文件中。这将确保如果做出导致后悔的数据处理决策，您仍然可以回到原始数据。

要执行此脚本，请在终端窗口中导航到 `src` 子文件夹，并运行命令 `r clean_data.R`。有关在命令行中工作的更多信息，请参阅[软件加工 shell 教程](http://software-carpentry.org/lessons/)。

项目目录现在应该是这样的。

```
|-- tomato_project
|   |-- data_raw
|   |   |-- raw_yield_data.csv
|   |   |-- README.txt
|   |-- data_clean
|   |   |-- clean_yield_data.csv
|   |-- results
|   |-- src
|   |   |-- clean_data.R 
```

### 第三阶段：数据分析

一旦数据经过检查和处理，基本可再现工作流程的第三阶段就是数据分析。当然，在这里可能会使用许多不同类型的分析方法，可能会得到许多不同类型的输出，包括基于文本的结果、表格和图形。在这个例子中，我们将执行一个非配对的双样本 t 检验，以确定传统和有机田间每株番茄产量的平均值是否有显著差异。

与数据处理类似，数据分析可以通过图形工具手动完成，比如电子表格程序。由于准确捕捉所有细节以便让第二个研究人员能够完全重复分析而没有错误的困难，这种方法并不推荐。数据分析也可以交互式地进行，将代码输入到一个“活”解释器窗口中，直到达到最终结果并保存。这一步通常很重要，因为它是探索的手段，可以确定用于分析的命令。然而，一旦交互式工具用于探索可能的方法，我们强烈建议将执行数据分析所需的所有命令放在单独的文件中，在执行时保存结果。

下面的代码应该保存在 `src` 目录中名为 `analysis.R` 的脚本中。运行时，它将读取清理过的数据表，执行所需的 t 检验，并将测试结果的摘要保存在 `results` 子文件夹中，保存为纯文本文件 `test_results.txt`。虽然这里不适用，但任何其他结果，如表格和图形，也应保存在 `results` 子文件夹中。

```
### Load clean data, assuming we are in the src directory
clean_yield_data <- read.csv("../data_clean/clean_yield_data.csv")

### t-test of Weights by Field type: is there significant difference in 
### tomato yield in the different fields?
t_test_Weight_Field <- with(clean_yield_data, t.test(Weight ~ Field)

### Write test result to plain text file 
capture.output(t_test_Weight_Field, file = "../results/test_results.txt") 
```

请注意，上面的代码中包含了描述分析步骤的几条注释。尽管这里的相对简单的命令不需要详细的解释，但在所有代码文件中应该大量使用注释，就像我们在这里的示例中所演示的那样。虽然代码本身描述了执行的*操作*是什么，但注释应该用来描述*为什么*，以及在更大的意义上*如何*进行所需的分析。虽然代码本身旨在重现分析的定量结果，但代码注释和其他文档旨在帮助另一个研究人员重现构建和编写代码的思维过程。

在这个阶段结束时，当脚本`analysis.R`像之前的`clean_data.R`脚本一样运行后，项目目录将如下所示。

```
|-- tomato_project
|   |-- data_raw
|   |   |-- raw_yield_data.csv
|   |   |-- README.txt
|   |-- data_clean
|   |   |-- clean_yield_data.csv
|   |-- results
|   |   |-- test_results.txt
|   |-- src
|   |   |-- analysis.R
|   |   |-- clean_data.R 
```

`test_results.txt`文件表明，在传统田地和有机田地的产量之间没有显著差异（p = 0.104）。

### 自动化

在这个阶段，可重现的工作流基本上已经完成。我们编写了一段代码，当执行时，将读取和处理我们的原始数据表，并保存清洁的数据表和我们分析的最终结果。最重要的是，任何有原始数据和我们编写的代码访问权限的研究人员都可以重现我们的分析结果，即传统和有机产量比较的 p 值。

为了使这个工作流更容易重现，可以添加一个控制器或驱动脚本来执行整个工作流的各个子组件。在这个简单的示例中，我们的工作流只有两个可以自动执行的步骤：执行`clean_data.R`生成清洁的数据表，然后执行`analysis.R`执行统计测试。

为了创建一个执行整个分析的单一入口点，我们可以创建一个 shell 脚本`runall.sh`，并将其保存在`src`目录中。对于这个简单的示例，脚本只包含两行。

```
r clean_data.R
r analysis.R 
```

要测试这个控制器脚本，删除`data_clean`和`results`目录的内容，以模拟向同事只提供原始数据和代码。从命令行中，导航到`src`目录并运行命令`sh runall.sh`，以查看工作流程的中间和最终结果重新生成。

除了支持可重复性外，创建类似于“一键式”工作流程还有一个相关的第二个好处，就是确保任何生成的结果直接链接到特定的已知数据集和分析参数。我们和许多同事已经知道，完成真实项目的工作后，会按照上述精确的步骤删除所有结果，并使用控制器脚本重新运行整个工作流程。这最后一步确保所有在后续解释和展示中使用的结果实际上都是从项目目录中的最新数据和代码生成的。

### 结论

虽然一些真实世界的工作流程几乎和这里显示的一样简单，但许多项目会更加复杂，甚至可能大不相同。这里显示的模板的最直接扩展将是需要适应更多种类的文件类型，包括许多类型的代码文件、几个类别的结果、二进制可执行文件和文档。从组织角度来看，在诸如`src`和`results`等文件夹内可以创建额外的子文件夹，以组织这些附加文件。主项目目录中的子文件夹，如`doc`和`bin`，可用于存放与文档相关的文件，包括手稿和已编译的二进制文件。

除了添加更多的项目文件之外，更复杂的项目将需要更复杂的工作流程，允许例如文件在多个项目之间共享，相同的分析在多个数据集或参数组合上运行，分析在远程计算机上运行等。这些额外的复杂性中的许多都在本卷中的案例研究中进行了讨论。

当超越上述描述的工具和技术时，我们首先建议您学习将版本控制软件整合到您的工作流程中。诸如`git`等软件的教程在网上很容易找到。

第二种可能的方向是尝试使用文学编程方法。这种方法涉及创建一个单一的源文档，使用诸如 Markdown 或 LaTeX 之类的语言，或者使用像 Sage 或 Jupyter 提供的“笔记本”界面，其中包含直接描述分析的文本以及代码、图表、表格和我们报告的其他结果。在这个框架中，可以执行单一的源文档来运行代码并获取结果，同时进行叙述描述和文档编写。这种方法提供了一个包含文本和代码的自包含文件，方便通过电子邮件传播给其他读者或提交出版。

总之，我们再次注意到，这个基本可重复的工作流程的结构，特别是将工作流程划分为三个核心阶段加上设置和自动化，构成了本卷描述的所有更复杂案例研究的基础。我们鼓励初学者和高级研究人员都将本章模板作为理解、组织和创建可重复工作流程的基本框架，作为数据密集型科学研究项目的一部分。
