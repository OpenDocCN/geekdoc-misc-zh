# 并行查询执行

> 原文：[`howqueryengineswork.com/14-parallel-query.html`](https://howqueryengineswork.com/14-parallel-query.html)

单线程查询引擎让大多数现代计算机处于闲置状态。我的台式机有 24 个 CPU 核心，但单线程查询只使用其中一个，浪费了 96%的计算能力。并行查询执行通过将工作分散到多个核心上来改变这一点。

目标很简单：如果一个查询在一个核心上需要 60 秒，那么在 12 个核心上运行应该接近 5 秒。由于协调开销和数据分布不均匀，我们很少能够实现完美的线性加速，但即使是部分并行化也能带来显著的改进。

本章介绍了在单台机器上使用多个线程或协程进行并行执行。下一章将扩展这些思想到多台机器的分布式执行，这引入了节点之间的网络协调和数据交换。

## 为什么并行化有帮助

查询引擎主要花费时间在三个活动上：从存储中读取数据、计算结果和写入输出。这些活动中的每一个都可以从并行化中受益。

对于 I/O 密集型的查询，它们大部分时间都在读取数据，并行化有助于提高效率，因为现代存储系统（SSDs、NVMe 驱动器）可以比顺序请求更快地处理多个并发读取请求。操作系统和存储控制器可以优化读取的顺序，并且多个线程保持 I/O 管道忙碌。

对于计算密集型的查询，它们花费时间在计算上（聚合、连接、复杂表达式），并行化直接乘以吞吐量。如果 12 个核心各自处理它们的数据份额，总时间接近单线程时间的十二分之一。

在实践中，大多数查询都是两者的混合体，并行化在这两种情况下都有帮助。

## 数据并行

我们将要探索的并行化形式被称为数据并行：同时在不同数据子集上运行相同的计算。如果我们有 1 亿行数据要处理，我们将它们分成块，并在不同的线程上处理每个块。

这与管道并行形成对比，在管道并行中，查询中的不同操作在不同的数据阶段上同时运行。管道并行更难实现，并且对于大多数查询工作负载的收益较少，因此大多数查询引擎都专注于数据并行。

数据并行需要输入数据被分区，即分成可以单独处理的独立块。自然的分区取决于数据是如何存储的。

## 一个实际例子

纽约市出租车数据集为并行执行提供了一个方便的测试用例。数据已经按月份分区，每月一个 CSV 文件，给我们提供了十二个分区来处理一年的数据。并行查询执行的最直接方法是每个分区使用一个线程，并行地在所有分区上执行相同的查询，然后组合结果。

*此示例的源代码可以在 KQuery GitHub 仓库中的 `jvm/examples/src/main/kotlin/ParallelQuery.kt` 找到。*

我们将使用 Kotlin 协程并行地对所有十二个月进行聚合查询。首先，这是查询单个分区的单线程函数：

```rs
fun executeQuery(path: String, month: Int, sql: String): List<RecordBatch> {
  val monthStr = String.format("%02d", month);
  val filename = "$path/yellow_tripdata_2019-$monthStr.csv"
  val ctx = ExecutionContext()
  ctx.registerCsv("tripdata", filename)
  val df = ctx.sql(sql)
  return ctx.execute(df).toList()
} 
```

使用这个辅助函数，我们可以在所有十二个分区上并行运行查询：

```rs
val start = System.currentTimeMillis()
val deferred = (1..12).map {month ->
  GlobalScope.async {

    val sql = "SELECT passenger_count, " +
        "MAX(CAST(fare_amount AS double)) AS max_fare " +
        "FROM tripdata " +
        "GROUP BY passenger_count"

    val start = System.currentTimeMillis()
    val result = executeQuery(path, month, sql)
    val duration = System.currentTimeMillis() - start
    println("Query against month $month took $duration ms")
    result
  }
}
val results: List<RecordBatch> = runBlocking {
  deferred.flatMap { it.await() }
}
val duration = System.currentTimeMillis() - start
println("Collected ${results.size} batches in $duration ms") 
```

在具有 24 个核心的桌面上运行会产生如下输出：

```rs
Query against month 8 took 17074 ms
Query against month 9 took 18976 ms
Query against month 7 took 20010 ms
Query against month 2 took 21417 ms
Query against month 11 took 21521 ms
Query against month 12 took 22082 ms
Query against month 6 took 23669 ms
Query against month 1 took 23735 ms
Query against month 10 took 23739 ms
Query against month 3 took 24048 ms
Query against month 5 took 24103 ms
Query against month 4 took 25439 ms
Collected 12 batches in 25505 ms 
```

总持续时间（25.5 秒）大致与最慢的单个查询相同（4 月为 25.4 秒）。所有十二个查询都是并发运行的，所以整体时间由最慢的分区决定，而不是所有分区的总和。单线程方法大约需要 250 秒（所有查询时间的总和）。

然而，我们现在有一个问题：结果是包含十二个批次的列表，每个批次都包含部分聚合。当我们想要一个单一组合结果时，每个分区都会有 `passenger_count=1` 的结果。

## 组合结果

我们如何组合并行执行的结果取决于查询的类型。

对于投影和过滤查询，结果可以简单地连接。如果每个分区都产生了过滤后的行，最终结果就是所有这些行的组合，类似于 SQL 的 `UNION ALL`。不需要进一步处理。

聚合查询需要一个两阶段的方法，通常使用“map-reduce”术语来描述。在“map”阶段，每个分区独立运行聚合。在“reduce”阶段，将这些部分结果组合成最终答案。

组合步骤使用相同的聚合函数 `MIN`、`MAX` 和 `SUM`。为了找到所有分区中的最小值，我们取每个分区最小值的最小值。相同的逻辑适用于最大值和总和。

`COUNT` 是不同的。我们不想计算计数的数量。我们想要计数的总和。如果分区 A 计数了 1000 行，分区 B 计数了 2000 行，总计数是 3000，而不是 2。

`AVG` 更加复杂。除非所有分区都有相同数量的行，否则平均值的平均值不是正确的整体平均值。正确的方法是分别计算总和和计数，然后在最后除以。一些查询引擎在规划阶段将 `AVG(x)` 重写为 `SUM(x) / COUNT(x)`，以正确处理并行聚合。

对于我们的出租车数据示例，我们在部分结果上运行二级聚合：

```rs
val sql = "SELECT passenger_count, " +
        "MAX(max_fare) " +
        "FROM tripdata " +
        "GROUP BY passenger_count"

val ctx = ExecutionContext()
ctx.registerDataSource("tripdata", InMemoryDataSource(results.first().schema, results))
val df = ctx.sql(sql)
ctx.execute(df).forEach { println(it) } 
```

这会产生最终的结果集：

```rs
1,671123.14
2,1196.35
3,350.0
4,500.0
5,760.0
6,262.5
7,80.52
8,89.0
9,97.5
0,90000.0 
```

## 分区策略

在我们的例子中，“每个文件一个线程”的策略效果很好，因为我们有十二个文件和大约十二个核心。但这种方法并不具有普遍性。如果我们有成千上万的小文件怎么办？为每个文件启动一个线程会创建过多的开销。如果我们有一个巨大的文件怎么办？一个线程会处理它，而其他线程则闲置。

一个更好的方法是分离分区（数据逻辑单元）和工作进程（线程或进程）的概念。然后查询计划器可以为每个工作进程分配多个分区，或将大型分区拆分到多个工作进程中，以平衡负载。

### 基于文件的分区

最简单的分区形式使用文件作为分区边界。每个文件成为一个分区。当文件大小大致相等且文件数量适合可用并行性时，这种方法效果很好。

### 行组分区

一些文件格式具有自然的内部分区。Apache Parquet 文件由多个“行组”组成，每个行组包含一批列式数据（通常是大约 128MB）。查询计划器可以检查可用的 Parquet 文件，枚举所有文件中的所有行组，并在固定的工作线程池中安排读取这些行组。

这比基于文件的分区提供了更细粒度的并行性。一个包含十个行组的单个大型 Parquet 文件可以由十个工作进程处理，而十个小型文件可能需要较少的工作进程来避免开销。

### 拆分非结构化文件

CSV 和其他文本格式缺乏内部结构，这使得它们更难进行分区。我们可以检查文件大小并将其分成相等的块，但记录边界并不与任意的字节偏移量对齐。一个记录可能跨越两个块。

解决方案是调整块边界以与记录边界对齐。在计算块边界的字节偏移量后，我们向前扫描以找到下一个记录分隔符（通常是换行符，但在包含换行符的引号字段中这会变得复杂）。然后每个工作进程都知道它应该处理的完整记录的确切字节范围。

这种复杂性是数据工程管道通常早期将 CSV 转换为 Parquet 的一个原因。Parquet 的结构化格式使得后续的并行处理变得简单得多。

## 分区修剪

当数据根据列值组织到分区中时，查询计划器可以跳过无法包含匹配行的整个分区。这种优化称为分区修剪。

一种常见的约定是使用包含键值对的目录名称来指示分区内容：

```rs
/mnt/nyctaxi/csv/year=2019/month=1/tripdata.csv
/mnt/nyctaxi/csv/year=2019/month=2/tripdata.csv
...
/mnt/nyctaxi/csv/year=2019/month=12/tripdata.csv 
```

给定这种结构，一个基于 `WHERE year = 2019 AND month = 3` 的查询可以只读取 2019 年 3 月的分区，完全跳过其他十一个月。这是在分区级别应用的一种谓词下推形式。

查询规划器检查过滤谓词，确定哪些引用分区键，并消除无法满足这些谓词的分区。对于像`WHERE month >= 6`这样的范围查询，规划器将包括 6 到 12 的分区，并排除 1 到 5 的分区。

分区修剪对于时间序列数据尤其有价值，因为查询通常集中在最近的时间段。一个良好的分区数据集可以将 I/O 减少几个数量级，与扫描所有数据相比。

## 并行连接

连接对并行执行比聚合提出了不同的挑战。对于聚合，我们可以独立处理分区并在最后合并结果。连接需要从两个不同的表中匹配行，而匹配的行可能位于不同的分区中。

### 广播连接

当连接的一侧足够小，可以完全放入内存时，最简单的并行策略是广播连接。我们将在每个工作器上完全将小表加载到内存中，然后每个工作器将大表的一部分与这个共享副本进行连接。

例如，将包含 10 亿行的`orders`表与包含 10,000 行的`products`表进行连接：每个工作器将所有 10,000 个产品加载到内存中，然后处理其分配的订单表分区，在处理过程中查找产品详情。在执行过程中不需要工作器之间的协调，因为每个工作器都有它需要的所有数据。

当小表确实很小的时候，广播连接效果很好。如果它变得太大，将副本复制到每个工作器的内存开销变得难以承受。

### 分区哈希连接

当连接的两侧都很大时，我们需要不同的方法：分区哈希连接（也称为并行哈希连接或洗牌哈希连接）。

关键的洞察是，只有当行的连接键匹配时，行才能进行连接。如果我们使用相同的分区方案通过连接键对两个表进行分区，那么可能进行连接的行最终会落在相应的分区中。然后我们可以在每一对分区上独立执行哈希连接。

考虑在`customer_id`上连接`orders`和`customers`。我们将两个表都通过散列`customer_id`到，比如说，16 个桶进行分区。客户 12345 的所有订单最终都会落在同一个桶中（可能是桶 7），客户 12345 的所有详细信息也会落在桶 7 中。然后工作器可以将订单的桶 7 与客户的桶 7 进行连接，完全独立于其他桶中的操作。

该过程有两个阶段：

1.  分区阶段：读取两个输入，并根据其连接键的哈希将每一行写入适当的分区。这重新分配了数据。

1.  连接阶段：对于每一对分区，执行标准的哈希连接。一方构建一个哈希表，另一方探测它。

分区阶段是成本较高的部分。它需要读取所有数据，计算哈希值，并写入临时存储（内存或磁盘）。对于跨多台机器的分布式执行，此阶段涉及网络传输，我们将在下一章中讨论。

## 重新分区和交换

分区哈希连接说明了通用概念：有时在查询执行过程中我们需要重新组织数据。数据以某种方式分区到达（可能是通过文件），但我们需要以不同的方式分区（通过连接键，或进入单个分区进行最终聚合）。

这种重新组织被称为重新分区或洗牌。执行此操作的运算符通常被称为交换操作符。

交换操作根据某种分区方案读取其输入分区并写入输出分区：

+   哈希分区：行根据一个或多个列的哈希值分配到分区。这用于连接和一些聚合。

+   轮询分区：行在分区之间均匀分布，不考虑内容。这在特定分区不重要时的负载均衡很有用。

+   单个分区：所有行都进入一个分区。这用于需要单个组合结果时的最终聚合或排序。

对于单机上的并行执行，交换操作可能会使用共享内存队列或临时文件在线程之间传递数据。对于分布式执行，它使用网络传输。逻辑概念是相同的；只是物理机制不同。

理解交换操作符很重要，因为它们代表了查询计划中并行性改变的点。我们将在下一章关于分布式执行的章节中进一步探讨这一点。

## 并行性的限制

并非每个查询都能从并行化中获得相同的好处。几个因素限制了我们可以实现多少速度提升。

Amdahl 定律：如果计算的一部分必须顺序运行，那么这个顺序部分限制了整体加速。90%的工作可以并行化的查询最多只能实现 10 倍的速度提升，无论我们投入多少核心，因为剩余的 10%仍然需要相同的时间。

协调开销：创建线程、分配工作以及收集结果都有成本。对于小数据集，这种开销可能会超过并行化节省的时间。存在一个最小数据集大小，低于这个大小单线程执行实际上更快。

内存压力：并行执行会乘以内存使用量。如果每个工人为连接构建一个哈希表，我们需要比单个工人多 12 倍的内存。当内存不足时，工人会溢出到磁盘，这会大大减慢速度。

不均匀的分区：如果某些分区比其他分区大，快速的工作者会提前完成并闲置，而慢速的工作者则需要完成更大的分区。整体时间由最慢的工作者决定。好的分区方案试图均匀分配工作，但这并不总是可行的。

I/O 带宽：并行化对 CPU 密集型工作比 I/O 密集型工作更有帮助。如果一个查询在磁盘或网络吞吐量上成为瓶颈，一旦我们饱和了可用带宽，增加更多的 CPU 核心就没有帮助了。

尽管存在这些限制，但在现代硬件上，并行执行为大多数分析查询提供了实质性的好处。关键在于理解何时它能有所帮助，何时开销不值得。

*本书也以 ePub、MOBI 和 PDF 格式可供购买，详情请访问[`leanpub.com/how-query-engines-work`](https://leanpub.com/how-query-engines-work)*

**版权所有 © 2020-2025 安迪·格鲁夫。保留所有权利。**
