# 17 号万圣节分析

|     17.1 第一个例子 |
| --- |
|     17.2 新形式的分析 |
|     17.3 示例：列表的队列 |
|       17.3.1 列表表示 |
|       17.3.2 第一次分析 |
|       17.3.3 更自由的操作序列 |
|       17.3.4 第二次分析 |
|       17.3.5 摊销与单个操作 |
|     17.4 进一步阅读 |

在预测增长中，我们介绍了大 O 复杂性的概念，以衡量计算的最坏情况时间。然而，正如我们在选择表示方法中看到的，当复杂性严重依赖于运行的确切操作序列时，这有时会是一个过于粗糙的界限。现在，我们将考虑一种不同风格的复杂性分析，更好地适应操作序列。

## 17.1 第一个例子

例如，考虑一个起初为空的集合，接着是一系列\(k\)个插入操作，然后是\(k\)个成员测试，假设我们使用没有重复的表示。插入时间与集合（和列表）的大小成正比；这最初是\(0\)，然后是\(1\)，依此类推，直到达到大小\(k\)。因此，插入序列的总成本是\(k \cdot (k+1) / 2\)。成员测试在最坏情况下每个需要花费\(k\)，因为我们已经向集合中插入了多达\(k\)个不同的元素。因此，总时间为

\begin{equation*}k² / 2 + k / 2 + k²\end{equation*}

总共\(2k\)个操作，平均产生

\begin{equation*}\frac{3}{4} k + \frac{1}{4}\end{equation*}

最坏情况下每个操作的步骤。

## 17.2 新形式的分析

我们计算了什么？我们仍然在计算最坏情况成本，因为我们已经在序列中每个操作的最坏情况下考虑了成本。然后，我们计算每个操作的平均成本。因此，这是最坏情况的平均值。重要的是，这与所谓的平均情况分析不同，后者使用概率论来计算计算的预估成本。我们这里没有使用任何概率。请注意，因为这是每个操作的平均值，它并不表示任何一个操作有多糟糕（正如我们将会看到的（摊销与单个操作），可能会更糟）；它只表示它们的平均值。

在上述情况下，这种新的分析并没有带来什么大的惊喜。我们发现，平均每次操作都花费大约\(k\)步；大 O 分析会告诉我们，我们正在执行\(2k\)个具有成本\(O([k \rightarrow k])\)的操作，其中 k 是不同元素的数量；每次操作，我们都会在最坏情况下执行大约线性工作的数量。

正如我们很快会看到的，然而，这并不总是这样：这种新的分析可能会带来惊喜。

在我们继续之前，我们应该给这个分析起个名字。正式地说，它被称为摊销分析。摊销是将付款分摊到一个延长但固定的期限内的过程。同样，我们将计算的成本分摊到一个固定的序列中，然后确定每次付款的金额。我给它起了一个古怪的名字，因为[Halloween](http://en.wikipedia.org/wiki/Halloween)是一个致力于鬼魂、鬼怪和其他死亡象征的（美国）节日。摊销来自拉丁词根 mort-，意思是死亡，因为摊销分析是在“死亡”时进行的，即在一系列固定的操作结束时进行的。

## 17.3 一个例子：列表中的队列

我们已经看到了列表[REF]和集合((part "sets"))。现在让我们考虑另一种基本的计算机科学数据结构：队列。队列是一种线性的、有序的数据结构，就像列表一样；然而，它们提供的操作集是不同的。在列表中，传统的操作遵循先进先出的原则：.first 返回最近链接的元素。相反，队列遵循先进先出的原则。也就是说，一个列表可以被视为堆栈，而一个队列可以被视为传送带。

### 17.3.1 列表表示

我们可以以自然的方式使用列表定义队列：每个入队都是通过链接实现的，而每个出队则需要遍历整个列表直到其末尾。相反，我们也可以使入队遍历到末尾，而出队对应于 .rest。无论哪种方式，其中一个操作将在表示队列的列表长度上花费恒定的时间，而另一个将是线性的。

事实上，上面的段落包含了一个关键的见解，这将让我们做得更好。

请注意，如果我们将队列存储在列表中，最近入队的元素放在前面，那么入队是廉价的（恒定时间）。相反，如果我们以相反的顺序存储队列，那么出队就是恒定时间的。如果我们能够两者兼得，那就太好了，但一旦我们选择了顺序，我们就必须放弃其中一个。除非我们选择...两者。

这一半很容易。我们只需将元素入队到列表中，最近添加的元素放在最前面。现在关键的（第一个）见解：当我们需要出队时，我们将列表反转。现在，出队也只需要恒定的时间。

### 17.3.2 第一次分析

当然，要完全分析这种数据结构的复杂性，我们还必须考虑到反转。在最坏的情况下，我们可以认为任何操作都可能反转（因为它可能是第一个出队）；因此，任何操作的最坏情况时间是反转所需的时间，这与列表长度成正比（这对应于队列的元素）。

然而，这个答案可能不令人满意。如果我们执行\(k\)个入队操作，然后是\(k\)个出队操作，那么每个入队操作都需要一步；最后\(k-1\)个出队操作中的每个都需要一步；只有第一个出队操作需要反转，这需要与列表中元素数量成正比的步骤，此时列表的长度为\(k\)。因此，此序列的操作总成本为\(k \cdot 1 + k + (k-1) \cdot 1 = 3k-1\)，共\(2k\)次操作，每个操作的摊销复杂度有效地为常数时间！

### 17.3.3 更自由的操作序列

在此过程中，我已经悄悄忽略了你可能注意到的一些事情：在我们的候选序列中，所有出队都紧跟着所有入队。下一个入队会发生什么？因为列表现在被反转了，所以它将需要花费线性数量的时间！所以我们只是部分解决了这个问题。

现在我们可以引入第二个见解：使用两个列表而不是一个。其中一个将是队列的尾部，新元素在其中入队；另一个将是队列的头部，元素在其中出队：

```
data Queue<T>:
  | queue(tail :: List<T>, head :: List<T>)
end

mt-q :: Queue = queue(empty, empty)
```

如果尾部被存储，以便最近的元素是第一个，那么入队操作只需要常数时间：

```
fun<T> enqueue(q :: Queue<T>, e :: T) -> Queue<T>:
  queue(link(e, q.tail), q.head)
end
```

要使出队操作花费常数时间，队列的头部必须以相反的方向存储。然而，任何元素如何从尾部移动到头部呢？很简单：当我们尝试出队并发现头部没有元素时，我们将整个尾部反转到头部（导致尾部为空）。我们将首先定义一个数据类型来表示出队的响应：

```
data Response<T>:
  | elt-and-q(e :: T, r :: Queue<T>)
end
```

现在来实现出队操作：

```
fun<T> dequeue(q :: Queue<T>) -> Response<T>:
  cases (List) q.head:
    | empty =>
      new-head = q.tail.reverse()
      elt-and-q(new-head.first,
        queue(empty, new-head.rest))
    | link(f, r) =>
      elt-and-q(f,
        queue(q.tail, r))
  end
end
```

### 17.3.4A 第二次分析

现在我们可以像之前一样推理操作序列，通过累加成本并求平均。然而，另一种思考方法是这样的。让我们给队列中的每个元素三个“信用”。每个信用可以用于一个常数时间操作。

一个信用在入队时被用完。只要元素保留在尾部列表中，它仍然有两个备用信用。当它需要移动到头部列表时，在反转的链接步骤中再花费一个信用。最后，出队操作也执行一次操作。

因为元素没有用尽信用，所以我们知道它必须有足够的信用。这些信用反映了对该元素的操作成本。通过这个（非常非正式的）分析，我们可以得出结论：在最坏的情况下，任何入队和出队的排列顺序仍然只需摊销的常数时间。

### 17.3.5 摊销与个别操作

请注意，这个常数代表了一系列操作的平均值。它并不限制任何一个操作的成本。事实上，正如我们在上面看到的，当出队操作发现头部列表为空时，它会反转尾部，这需要与尾部大小成线性时间—<wbr>根本不是常数！因此，我们应该小心，不要假设序列中的每一步都是有界的。然而，摊销分析有时会给我们比最坏情况分析更加细致的了解数据结构真实行为。

## 17.4 阅读更多

到目前为止，我只是简要涉及了摊销分析的主题。一篇非常好的[由 Rebecca Fiebrink 撰写的教程](http://www.cs.princeton.edu/~fiebrink/423/AmortizedAnalysisExplained_Fiebrink.pdf)提供了更多信息。算法权威书籍《算法导论》由 Cormen、Leiserson、Rivest 和 Stein 详细介绍了摊销分析。
