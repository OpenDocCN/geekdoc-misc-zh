# 21 利用状态的算法

|     21.1 并查集再谈 |
| --- |
|       21.1.1 优化 |
|       21.1.2 分析 |
|     21.2 哈希再谈 |
|       21.2.1 提高访问时间 |
|       21.2.2 更好的哈希 |
|       21.2.3 布隆过滤器 |
|     21.3 通过记住答案避免重新计算 |
|       21.3.1 一个有趣的数列 |
|         21.3.1.1 利用状态记住过去的答案 |
|         21.3.1.2 从计算树到 DAG |
|         21.3.1.3 数字的复杂性 |
|         21.3.1.4 抽象化记忆化 |
|       21.3.2 拼写纠正的编辑距离 |
|       21.3.3 自然作为一个肥手指的打字员 |
|       21.3.4 动态规划 |
|         21.3.4.1 动态规划求解卡塔兰数 |
|         21.3.4.2 编辑距离与动态规划 |
|       21.3.5 记忆化和动态规划的对比 |

## 21.1 并查集再谈

下面是我们如何使用这个来重新实现并查集。我们将尽量保持与之前版本 (检查组件连接性) 尽可能相似，以便进行比较。

首先，我们必须更新元素的定义，使父节点字段可变：

```
data Element:
  | elt(val, ref parent :: Option<Element>)
end
```

要确定两个元素是否属于同一个集合，我们仍然依赖于查找操作。然而，正如我们很快会看到的那样，查找操作不再需要整个元素集合。因为确定两个元素是否属于同一个集合的唯一原因是为了将其传递给查找操作，所以我们可以从这里将其删除。除此之外，没有其他变化：

```
fun is-in-same-set(e1 :: Element, e2 :: Element) -> Boolean:
  s1 = fynd(e1)
  s2 = fynd(e2)
  identical(s1, s2)
end
```

现在更新已经成为关键的区别：我们使用突变来改变父节点的值：

```
fun update-set-with(child :: Element, parent :: Element):
  child!{parent: some(parent)}
end
```

在 parent：some(parent) 中，第一个父元素是字段的名称，而第二个父元素是参数的名称。此外，我们必须使用 some 来满足选项类型。自然，它不是 none，因为这种变异的整个目的是将父元素更改为其他元素，而不管之前是什么。在给定这个定义后，联合操作也基本保持不变，除了返回类型的变化。以前，它需要返回更新后的元素集；现在，因为更新是通过变异执行的，所以不再需要返回任何东西：

```
fun union(e1 :: Element, e2 :: Element):
  s1 = fynd(e1)
  s2 = fynd(e2)
  if identical(s1, s2):
    s1
  else:
    update-set-with(s1, s2)
  end
end
```

最后，fynd。它的实现现在非常简单。不再需要搜索集合。以前，我们必须搜索，因为联合操作发生后，父引用可能不再有效。现在，任何这样的变化都会自动反映在变异中。因此：

```
fun fynd(e :: Element) -> Element:
  cases (Option) e!parent:
    | none => e
    | some(p) => fynd(p)
end
```

### 21.1.1 优化

再次看看 fynd。在某些情况下，与 e 绑定的元素不是集合名称；这是通过递归遍历父引用获得的。然而，当这个值返回时，我们却没有做任何事情来反映这个新知识！相反，下次我们尝试找到这个元素的父元素时，我们将再次执行相同的递归遍历。

使用变异有助于解决这个问题。这个想法非常简单：计算父元素的值，并更新它。

```
fun fynd(e :: Element) -> Element:
  cases (Option) e!parent block:
    | none => e
    | some(p) =>
      new-parent = fynd(p)
      e!{parent: some(new-parent)}
      new-parent
  end
end
```

请注意，此更新将应用于递归链中的每个元素，以找到集合名称。因此，下次应用 fynd 到其中任何一个元素时都将受益于此更新。这个想法被称为路径压缩。

我们还可以应用另一个有趣的想法。这就是维护每个元素的等级，它大致是该元素的元素树的深度，这个树的元素是它们的集合名称。当我们联合两个元素时，我们将等级较大的元素作为等级较小的元素的父元素。这样做的效果是避免使通向集合名称元素的路径变得非常长，而是倾向于“树状”树。这也减少了必须遍历以找到代表的父元素的数量。

### 21.1.2 分析

这个优化后的并查集数据结构有着非凡的分析。在最坏的情况下，当然，我们必须遍历整个父链才能找到名称元素，这需要的时间与集合中的元素数量成正比。然而，一旦我们应用了上述优化，我们就再也不需要再次遍历同样的链了！特别是，如果我们对一系列集合相等性测试进行摊销分析，然后进行一系列的联合操作，我们发现后续检查的成本非常小——实际上，几乎是一个函数可以达到的最小值，而不是常数。[实际分析](http://en.wikipedia.org/wiki/Disjoint-set_data_structure)非常复杂；它也是计算机科学中最显著的算法分析之一。

## 21.2 通过哈希重新设置成员资格

我们已经看到了关于集合成员资格的解决方案。首先，我们看到了如何将集合表示为列表（通过列表表示集合），然后是作为（平衡的）二叉树（一个很好的平衡：树手术）。不要将此与并查集混淆，后者是关于集合的不同类型的问题（不相交集合 Redux）。通过这样做，我们能够将插入和成员资格降低到元素数量的对数时间。在这个过程中，我们还学会了使用这些表示的本质是将任何数据类型转换为可比较的、有序的元素—为了效率，通常是一个数字（将值转换为有序值
```

我们需要使用模运算找到正确的桶：

```
fun find-bucket(n): num-modulo(n, SIZE) end
```

通过这个，我们可以确定一个元素是否在集合中：

```
fun get-bucket(n): array-get-now(v, find-bucket(n)) end
fun is-in(n): get-bucket(n).member(n) end
```

要实际将元素添加到集合中，我们将其放入与适当桶相关联的列表中：

```
fun set-bucket(n, anew): array-set-now(v, find-bucket(n), anew) end
fun put(n):
  when not(is-in(n)):
    set-bucket(n, link(n, get-bucket(n)))
  end
end
```

检查元素是否已在桶中是我们复杂性论证的重要部分，因为我们隐含地假设桶中不会有重复元素。

> 练习
> 
> > 重复元素对操作的复杂性有什么影响？

我们上面定义的数据结构称为哈希表（这是一个稍微令人困惑的名称，因为它实际上不是一个哈希表，但这是计算机科学中惯用的名称）。

### 21.2.2 更好的哈希

使用数组似乎解决了一个问题：插入。找到相关的桶需要常量时间，链接新元素需要常量时间，因此整个操作需要常量时间……除非，我们还必须检查元素是否已经在桶中，以避免存储重复项。我们已经摆脱了遍历代表集合的外部列表，但是对内部列表的成员操作保持不变。原则上不会发生变化，但在实践中我们可以做得更好。

请注意，碰撞几乎是不可避免的。如果我们有均匀分布的数据，那么碰撞会比我们预期的要早出现。这是由于所谓的[生日问题](http://en.wikipedia.org/wiki/Birthday_problem)背后的推理，通常被表述为在房间里需要多少人才能使其中两个人共享生日的可能性超过某个百分比。为了使可能性超过一半，我们只需要 23 个人！因此，明智的做法是为碰撞的可能性做好准备。

关键是要了解散列值的分布情况。例如，如果我们知道我们的散列值都是 10 的倍数，那么使用大小为 10 的表是一个糟糕的主意（因为所有元素都会散列到同一个桶中，将我们的散列表变成一个列表）。在实践中，通常使用不常见的素数作为表的大小，因为随机值不太可能具有它作为除数。这并不会产生理论上的改进（除非你可以对输入进行某些假设，或者非常仔细地进行数学推导），但在实践中效果很好。特别是，由于典型的散列函数使用堆上对象的内存地址，而大多数系统上这些地址都是 4 的倍数，因此使用 31 这样的素数通常是一个相当好的选择。

### 21.2.3Bloom Filters

另一种改善空间和时间复杂度的方法是放宽我们对操作期望的属性。现在，集合成员关系给出了完美的答案，即当被检查的元素先前插入到集合中时，它准确地回答 true。但是假设我们处于一个可以接受更放松的正确性概念的环境中，在这种情况下，成员关系测试可能会在一定程度上“撒谎”（但不是两者都，因为这使得表示几乎没有用处）。具体来说，让我们说“不意味着没有”（即，如果集合表示说元素不存在，则确实不存在），但“是有时意味着没有”（即，如果集合表示一个元素存在，则有时可能不存在）。简而言之，如果集合说元素不在其中，这应该是有保证的；但是如果集合说元素存在，则可能不存在。在后一种情况下，我们需要一些其他——更昂贵的——技术来确定真相，或者我们可能根本不在乎。

这种数据结构在哪里有用？假设我们正在构建一个使用基于密码的身份验证的网站。由于许多密码在广为宣传的泄露中被泄露，可以安全地假设黑客已经获取了它们并会猜测它们。因此，我们不希望允许用户选择任何这些密码作为密码。我们可以使用哈希表来精确拒绝已知的泄露密码。但为了效率，我们可以使用这个不完美的哈希。如果它说“不”，那么我们允许用户使用该密码。但如果它说“是”，那么要么他们正在使用一个已泄露的密码，要么他们有一个完全不同的密码，纯粹是偶然的，具有相同的哈希值，但无论如何；我们可以禁止那个密码。一个相关的用途是用于过滤恶意网站。URL 缩短系统 bitly，[用于此目的](http://word.bitly.com/post/28558800777/dablooms-an-open-source-scalable-counting-bloom)。

另一个例子是更新数据库或内存存储。假设我们有一个记录的数据库，我们经常更新。通常更有效的方法是维护一份更改日志：即，按顺序记录所有已发生的更改的列表。在某个间隔（比如说每夜），日志被“刷新”，意味着所有这些更改都被应用到数据库中。但这意味着每个读取操作变得非常低效，因为它必须先检查整个日志（以查找更新）再访问数据库。同样，在这里我们可以使用这个错误的哈希表概念：如果记录定位器的哈希说“不”，那么记录肯定没有被修改，我们直接访问数据库；如果它说“是”，那么我们必须检查日志。

我们已经在此前看过这个想法的一个简单示例实现，当时我们使用了一个布尔值的单个列表（或数组），带有模运算，来表示集合。当集合说 4 不在时，这是绝对正确的；但当它说 5 和 10 都存在时，只有其中一个存在。优点是节省了大量的空间和时间：我们只需要每个桶一个位，并且不需要搜索列表来回答成员资格。当然，缺点是一个极不准确的集合数据结构，以及与模数相关的失败。

有一种简单的方法可以改进这个解决方案：不再只有一个数组，而是有几个（但数量固定）。当一个元素被添加到集合中时，它被添加到每个数组中；在检查成员资格时，要查看每个数组。只有当所有数组都同意时，集合才会肯定地回答成员资格。

自然地，如果多个数组的大小都相同，则使用多个数组不会提供任何优势：由于插入和查找都是确定性的，所有数组都将得到相同的答案。然而，有一个简单的解决方法：使用不同的数组大小。特别地，通过使用彼此相对质数的数组大小，我们最小化了冲突的可能性（只有所有数组大小的乘积才会欺骗数组）。

这种数据结构，称为布隆过滤器，是一种概率性数据结构。与我们之前的集合数据结构不同，这个数据结构不能保证始终给出正确的答案；但与☛时空权衡相反，通过稍微改变问题接受不正确的答案，我们既节省了空间又节省了时间。如果我们对哈希值的分布有所了解，并且有一些可接受的误差范围，我们可以设计哈希表大小，以便在很大概率下，布隆过滤器将在可接受的误差范围内。

## 21.3 通过记忆答案避免重新计算

我们已经在几个实例中提到了☛时空权衡。最明显的权衡是当计算“记住”先前的结果，并且不重新计算它们，而是查找它们并返回答案时。这是权衡的一个例子，因为它使用空间（记住先前的答案）来代替时间（重新计算答案）。让我们看看如何编写这样的计算。

### 21.3.1 一个有趣的数字序列

假设我们想要创建正确括号表达式，并忽略所有非括号符号。给定一定数量的开括号（或者相同数量的闭括号），创建括号表达式的方式有多少种？

如果我们没有开括号，我们唯一能够创建的表达式是空表达式。如果我们有一个开括号，我们唯一能够构建的是“()”（必须有一个闭括号，因为我们只关心正确括号的表达式）。如果我们有两个开括号，我们可以构建“(())”和“()()”。给定三个，我们可以构建“((()))”、“(())()”、“()(())”、“()()()”和“(()())”，总共五个。以此类推。观察到每个级别的解决方案都使用了低一级别的所有可能解决方案，并以所有可能的方式组合。

实际上，有一个与这些表达式数量对应的著名数学序列，称为[卡塔兰数列](http://en.wikipedia.org/wiki/Catalan_number)。它具有快速增长的特性：从上述谦逊的起源开始，第十个卡塔兰数（即卡塔兰数列的第十个元素）为 16796。一个简单的递推公式给出了卡塔兰数，我们可以将其转换为简单的程序：

```
fun catalan(n):
  if n == 0: 1
  else if n > 0:
    for fold(acc from 0, k from range(0, n)):
      acc + (catalan(k) * catalan(n - 1 - k))
    end
  end
end
```

这个函数的测试如下：<wbr><catalan-tests> ::=

|   check: |
| --- |
|     catalan(0) is 1 |
|     catalan(1) is 1 |
|     catalan(2) 是 2 |
|     catalan(3) 是 5 |
|     catalan(4) 是 14 |
|     catalan(5) 是 42 |
|     catalan(6) 是 132 |
|     catalan(7) 是 429 |
|     catalan(8) 是 1430 |
|     catalan(9) 是 4862 |
|     catalan(10) 是 16796 |
|     catalan(11) 是 58786 |
|   end |

但要注意！当我们计算函数的执行时间时，我们发现前几个测试运行速度非常快，但在值在 10 到 20 之间的某处—<wbr>取决于您的机器和编程语言实现—<wbr>您应该看到事情开始变慢，一开始是一点点，然后效果极其明显。

> 现在做！
> 
> > 查看您的计算机在何时开始观察到明显的减速。绘制运行时间与输入大小的图表。这意味着什么？

正如我们之前所暗示的那样，使 Catalan 计算如此耗时的原因正是因为在每个级别，我们依赖于计算所有较小级别的 Catalan 数；这个计算反过来又需要它所有较小级别的数字；依此类推。

> 练习
> 
> > 映射 catalan 的子计算，以了解计算时间为何会爆炸。这个函数的渐近时间复杂度是多少？

### 21.3.1.1 利用状态记住以前的答案

因此，这显然是一种通过交换空间换取时间可能有所帮助的情况。我们如何做到这一点？我们需要一种记住所有先前答案并在后续尝试计算它们时检查它们是否已知的内存概念，如果是，只返回它们而不是重新计算它们。

> 现在做！
> 
> > 这是基于什么关键假设？

当然，这假设对于给定的输入，答案将始终相同。正如我们所见，具有状态的函数大量违反了这一假设，因此典型的有状态函数无法利用这种优化。具有讽刺意味的是，我们将使用状态来实现这种优化，因此我们将有一个有状态的函数，它在给定的输入上始终返回相同的答案—<wbr>从而使用状态在有状态的函数中模拟无状态的函数。酷毙了，伙计！

首先，我们需要一些内存的表示。我们可以想象几种，但这里有一个简单的：

```
data MemoryCell:
  | mem(in, out)
end

var memory :: List<MemoryCell> = empty
```

如何修改 catalan？我们首先要查看值是否已经存在于内存中；如果存在，则无需进一步计算，直接返回它，但如果不存在，则计算结果，将其存储在内存中，然后返回它：

```
fun catalan(n :: Number) -> Number:
  answer = find(lam(elt): elt.in == n end, memory)
  cases (Option) answer block:
    | none =>
      result =
        if n == 0: 1
        else if n > 0:
          for fold(acc from 0, k from range(0, n)):
            acc + (catalan(k) * catalan(n - 1 - k))
          end
        end
      memory := link({in: n, out: result}, memory)
      result
    | some(v) => v.out
  end
end
```

就是这样！现在运行我们以前的测试会发现答案计算速度更快，但另外我们可以尝试运行更大的计算，比如 catalan(50)。

这个过程，将一个函数转换为记住其过去答案的版本，称为记忆化。

### 21.3.1.2 从计算树到 DAG

我们巧妙地做了一件事，那就是将计算树转换为相同计算的 DAG，重复使用等价调用。而以前每个调用都会生成大量递归调用，这些调用又会导致更多的递归调用，现在我们重新使用以前的递归调用—<wbr>即，共享先前计算的结果。这实际上是将递归调用指向之前发生的递归调用。因此，计算形状从树转换为调用的 DAG。

这具有重要的复杂性优势。而以前我们执行了超指数数量的调用，现在我们每个输入只执行一次调用，并共享所有以前的调用—<wbr>从而将 catalan(n)减少到与 n 成比例的新调用数量。查找以前调用的结果需要与内存大小成比例的时间（因为我们将其表示为列表；更好的表示方法会改善这一点），但这只会增加另一个线性乘法因子，将整体复杂性降低到与输入大小的二次方成比例。这是整体复杂性的显著降低。相比之下，记忆化的其他用途可能导致改进远不及这么明显，将该技术的使用转变为真正的工程权衡。

### 21.3.1.3 数字的复杂性

随着我们开始运行更大的计算，我们可能会注意到我们的计算所花费的时间开始超过线性增长。这是因为我们的数字正在任意变大—<wbr>例如，catalan(100)是 896519947090131496687170070074100632420837521538745909320—<wbr>并且对数字的计算不再是常数时间，与我们之前所说的相反（输入的大小）。事实上，在处理密码问题时，数字操作不是常数时间非常关键，这是基本复杂性结果的关键（例如，当代密码学的假设无法破解）。

### 21.3.1.4 记忆化的抽象

现在我们已经实现了所期望的复杂性改进，但是我们修订后的 catalan 定义结构仍然有些不尽如人意：记忆化的行为与 Catalan 数的定义深度交织在一起，尽管这两者应该在智力上是不同的。我们接下来做这件事。

实际上，我们想将我们的程序分成两部分。一部分定义了记忆化的一般概念，而另一部分则根据这个一般概念定义了 catalan。

前者的意思是什么？我们想要封装“内存”的概念（因为我们大概不希望将其存储在任何程序的任意部分都可以修改的变量中）。这应该会产生一个函数，它接受我们想要检查的输入；如果在内存中找到了它，我们就返回那个答案，否则我们计算答案，存储它，并返回它。为了计算答案，我们需要一个确定如何计算的函数。将这些部分组合在一起：

```
data MemoryCell:
  | mem(in, out)
end

fun memoize-1<T, U>(f :: (T -> U)) -> (T -> U):

  var memory :: List<MemoryCell> = empty

  lam(n):
    answer = find(lam(elt): elt.in == n end, memory)
    cases (Option) answer block:
      | none =>
        result = f(n)
        memory := link({in: n, out: result}, memory)
        result
      | some(v) => v.out
    end
  end
end
```

我们使用`memoize-1`这个名称来指示这是一个针对单参数函数的记忆化器。请注意，上面的代码几乎与之前的代码相同，除了我们之前的卡特兰数计算逻辑，现在有了参数`f`决定要做什么。有了这个，我们现在可以这样定义卡特兰数：

```
rec catalan :: (Number -> Number) =
  memoize-1(
    lam(n):
      if n == 0: 1
      else if n > 0:
        for fold(acc from 0, k from range(0, n)):
          acc + (catalan(k) * catalan(n - 1 - k))
        end
      end
    end)
```

注意以下关于这个定义的几点：

1.  我们不写`fun catalan(...): ...;`，因为绑定到`catalan`的过程是由`memoize-1`生成的。

1.  请注意，对`catalan`的递归调用必须是对与记忆化结果绑定的函数，从而像对象一样行为（对象：解释与类型）。未能引用同一个共享过程意味着递归调用将不会被记忆化，从而失去了这一过程的好处。

1.  我们需要使用`rec`，这是我们之前看到的原因[递归函数]。

1.  每次调用`memoize-1`都会创建一个新的存储结果的表。因此，不同函数的记忆化将各自拥有自己的表，而不是共享表，这是一个不好的主意！

如果对状态如何与函数交互有疑问，请阅读状态与闭包的交互：计数器。

> 练习
> 
> > 为什么共享记忆表是一个坏主意？具体点。

### 21.3.2 拼写纠正的编辑距离

文本编辑器、文字处理器、手机以及各种其他设备现在通常都实现了拼写纠正或提供对（拼写错误的）建议。它们是如何做到这一点的呢？这需要两个能力：计算单词之间的距离，以及根据这个度量找到附近的单词。在本节中，我们将研究这两个问题中的第一个。（在讨论的目的上，我们不会深入讨论“单词”究竟是什么的确切定义，只是处理字符串。一个真实的系统需要详细关注这个定义。）

> 现在动手吧！
> 
> > 想想你可能如何定义“两个单词之间的距离”。它定义了[度量空间](http://en.wikipedia.org/wiki/Metric_space)吗？
> > 
> 练习
> 
> > 我们给出的定义将在单词集合上定义一个度量空间吗？

虽然可能有几种合理的定义单词之间的距离的方法，但我们在这里关心的是在拼写错误的非常特定的上下文中的距离。给定距离度量，一个用途可能是计算给定单词与字典中所有单词的距离，并提供最接近的单词（即，距离最小的单词）作为建议的更正。显然，我们无法计算每个输入的单词与大型字典中每个单词之间的距离。使这个过程有效的另一半构成了这个问题的另一半。简而言之，我们需要快速地将大多数单词丢弃，因为它们不够接近，对于这一点，如[词袋模型](http://en.wikipedia.org/wiki/Bag-of-words_model)（这里是字符袋）这样的表示可以极大地帮助。考虑到这样的预期用途，我们至少希望以下内容保持不变：

+   单词到自身的距离为零。

+   单词与除自身之外的任何单词的距离严格为正。（否则，给定一个已在字典中的单词，“修正”可能是另一个不同的字典单词。）

+   两个单词之间的距离是对称的，即，传递参数的顺序不应该影响结果。

> 练习
> 
> > 请注意，相对于度量的属性，我们没有包含三角不等式。为什么不呢？如果我们不需要三角不等式，这是否让我们定义更有趣的不是度量的距离函数？

给定一对单词，假设我们打算输入一个单词，但实际上输入了另一个。在这里，也有几种可能的定义，但一个流行的定义认为有三种手指大的方法：

1.  我们漏掉了一个字符；

1.  我们打了一个字符两次；或者，

1.  当我们的意思是另一个字符时，我们输入了一个字符。

特别地，我们对这些形式需要执行的最少编辑感兴趣，以从一个单词到另一个单词。出于自然的原因，这种距离概念被称为编辑距离或者，为了纪念其创建者，称为莱文斯坦距离。更多详情请见[Wikipedia](http://en.wikipedia.org/wiki/Levenshtein_distance)。

这个定义有几种可能的变体。目前，我们将考虑最简单的一种，它假设每个错误都具有相等的成本。对于某些输入设备，我们可能希望对这些错误分配不同的成本；我们也可能根据输入了哪个错误字符来分配不同的成本（键盘上相邻的两个字符更有可能是合法错误，而不是相隔很远的两个字符）。我们稍后会简要回顾其中一些考虑（自然作为手指大的打字员）。

在这个度量下，“kitten”和“sitting”的距离是 3，因为我们必须用“s”替换“k”，用“i”替换“e”，并插入“g”（或者对称地，执行相反的替换并删除“g”）。以下是更多的例子：<levenshtein-tests> ::=

|   check: |
| --- |
|     levenshtein(empty, empty) 是 0 |
|     levenshtein([list:"x"], [list: "x"]) 是 0 |
|     levenshtein([list: "x"], [list: "y"]) 是 1 |
|     # 其中之一约为 600 |
|     levenshtein( |
|       [list: "b", "r", "i", "t", "n", "e", "y"], |
|       [list: "b", "r", "i", "t", "t", "a", "n", "y"]) |
|       是 3 |
|     # http://en.wikipedia.org/wiki/Levenshtein_distance |
|     levenshtein( |
|       [list: "k", "i", "t", "t", "e", "n"], |
|       [list: "s", "i", "t", "t", "i", "n", "g"]) |
|       是 3 |
|     levenshtein( |
|       [list: "k", "i", "t", "t", "e", "n"], |
|       [list: "k", "i", "t", "t", "e", "n"]) |
|       是 0 |
|     # http://en.wikipedia.org/wiki/Levenshtein_distance |
|     levenshtein( |
|       [list: "S", "u", "n", "d", "a", "y"], |
|       [list: "S", "a", "t", "u", "r", "d", "a", "y"]) |
|       是 3 |
|     # http://www.merriampark.com/ld.htm |
|     levenshtein( |
|       [list: "g", "u", "m", "b", "o"], |
|       [list: "g", "a", "m", "b", "o", "l"]) |
|       是 2 |
|     # http://www.csse.monash.edu.au/~lloyd/tildeStrings/Alignment/92.IPL.html |
|     levenshtein( |
|       [list: "a", "c", "g", "t", "a", "c", "g", "t", "a", "c", "g", "t"], |
|       [list: "a", "c", "a", "t", "a", "c", "t", "t", "g", "t", "a", "c", "t"]) |
|       是 4 |
|     levenshtein( |
|       [list: "s", "u", "p", "e", "r", "c", "a", "l", "i", |
|         "f", "r", "a", "g", "i", "l", "i", "s", "t" ], |
|       [list: "s", "u", "p", "e", "r", "c", "a", "l", "y", |
|         "f", "r", "a", "g", "i", "l", "e", "s", "t" ]) |
|       是 2 |
|   end |

基本算法实际上非常简单：<levenshtein> ::=

|   rec levenshtein :: (List<String>, List<String> -> Number) = |
| --- |
|     <levenshtein-body> |

在这里，因为有两个列表输入，有四种情况，其中两种是对称的：<levenshtein-body> ::=

|   lam(s, t): |
| --- |
|     <levenshtein-both-empty> |
|     <levenshtein-one-empty> |
|     <levenshtein-neither-empty> |
|   end |

如果两个输入都为空，则答案很简单：<levenshtein-both-empty> ::=

|   if is-empty(s) and is-empty(t): 0 |
| --- |

当其中一个为空时，编辑距离对应于另一个的长度，需要完全插入（或删除）（因此我们每个字符收取一次费用）：<levenshtein-one-empty> ::=

|   else if is-empty(s): t.length() |
| --- |
|   else if is-empty(t): s.length() |

如果两者都不为空，则每个都有一个第一个字符。 如果它们相同，则与此字符相关联的编辑成本为零（我们在不增加编辑成本的情况下反复对单词的其余部分进行反射）。 但是，如果它们不同，我们考虑每种可能的编辑：<levenshtein-neither-empty> ::=

|   else: |
| --- |
|     如果 s.first == t.first: |
|       levenshtein(s.rest, t.rest) |
|     else: |
|       min3( |
|         1 + levenshtein(s.rest, t), |
|         1 + levenshtein(s, t.rest), |
|         1 + levenshtein(s.rest, t.rest)) |
|     end |
|   end |

在第一种情况下，我们假设 s 多了一个字符，因此我们计算成本，就像我们要删除它并为其余的字符串找到最低成本一样（但为此删除收取一个成本）；在第二种情况下，我们对称地假设 t 多了一个字符；在第三种情况下，我们假设一个字符被另一个字符替换了，所以我们收取一个成本，但考虑两个单词的其余部分（例如，假设“s”被输入为“k”，并继续处理“itten”和“itting”）。这使用了以下辅助函数：

```
fun min3(a :: Number, b :: Number, c :: Number):
  num-min(a, num-min(b, c))
end
```

这个算法确实会通过我们上面编写的所有测试，但有一个问题：运行时间呈指数增长。这是因为每次我们找到一个不匹配时，我们都会在三个子问题上进行递归。因此，原则上，算法的时间与较短单词的长度的三次方成正比。实际上，任何与之匹配的前缀都不会引起分支，因此是不匹配引起分支（因此，确认一个单词与自身的距离为零仅需要与单词大小成线性时间）。

注意，然而，许多这些子问题是相同的。例如，给定“kitten”和“sitting”，初始字符的不匹配会导致算法计算“itten”与“itting”的距离，但也会计算“itten”与“sitting”以及“kitten”与“itting”的距离。后两个距离计算也将涉及将“itten”与“itting”进行匹配。因此，我们再次希望计算树变成实际计算的表达式的 DAG。

因此，解决方案自然是使用记忆化。首先，我们需要一个可以处理两个参数而不是一个的记忆器：

```
data MemoryCell2<T, U, V>:
  | mem(in-1 :: T, in-2 :: U, out :: V)
end

fun memoize-2<T, U, V>(f :: (T, U -> V)) -> (T, U -> V):

  var memory :: List<MemoryCell2<T, U, V>> = empty

  lam(p, q):
    answer = find(
      lam(elt): (elt.in-1 == p) and (elt.in-2 == q) end,
      memory)
    cases (Option) answer block:
      | none =>
        result = f(p, q)
        memory :=
        link({in-1: p, in-2: q, out: result}, memory)
        result
      | some(v) => v.out
    end
  end
end
```

大多数代码都没有变化，只是我们存储了两个参数而不是一个，并相应地查找两个。有了这个，我们可以重新定义 levenshtein 以使用记忆化：<levenshtein-memo> ::=

|   rec levenshtein :: (List<String>, List<String> -> Number) = |
| --- |
|     memoize-2( |
|       lam(s, t): |
|         if is-empty(s) and is-empty(t): 0 |
|         else if is-empty(s): t.length() |
|         else if is-empty(t): s.length() |
|         else: |
|           if s.first == t.first: |
|             levenshtein(s.rest, t.rest) |
|           else: |
|             min3( |
|               1 + levenshtein(s.rest, t), |
|               1 + levenshtein(s, t.rest), |
|               1 + levenshtein(s.rest, t.rest)) |
|           end |
|         end |
|       end) |

其中 memoize-2 的参数正是我们先前见过的<levenshtein-body>（现在你知道为什么我们略微奇怪地定义了 levenshtein，而不是使用 fun）。

这个算法的复杂性仍然不容忽视。首先，让我们介绍后缀这个术语：字符串的后缀是从字符串的任何点开始的剩余部分。（因此，“kitten”，“itten”，“ten”，“n”和“”都是“kitten”的后缀。）现在，请注意，在最坏的情况下，从第一个单词的每个后缀开始，我们可能需要对第二个单词的每个后缀执行比较。幸运的是，对于这些后缀中的每一个，我们相对于递归执行一个恒定的计算。因此，计算长度为\(m\)和\(n\)的字符串之间的距离的总体时间复杂度是\(O([m, n \rightarrow m \cdot n])\)。（我们稍后会回到空间消耗问题[对比备忘录和动态规划]。）

> 练习
> 
> > 修改上述算法以产生一个实际（最佳）的编辑操作序列。有时这被称为回溯。

### 21.3.3 自然界如同一个手残的打字员

我们已经谈论了如何解决人类的错误。然而，人类并不是唯一的糟糕的打字员：自然也是之一！

当研究生物体时，我们获得了由氨基酸和其他化学物质组成的分子的序列，如 DNA，这些分子包含有关生物体的重要且潜在决定性的信息。这些序列由我们希望识别的相似片段组成，因为它们代表了生物体行为或进化中的关系。[某些州和国家](http://en.wikipedia.org/wiki/Creation_and_evolution_in_public_education)中可能需要跳过本节。不幸的是，这些序列永远不会完全相同：就像所有低级程序员一样，自然有时会在复制过程中出错（称为——等待它——突变）。因此，寻找严格的相等性会排除太多几乎可以肯定是等价的序列。相反，我们必须执行一个对齐步骤来找到这些等价序列。正如你可能已经猜到的那样，这个过程非常像计算编辑距离的过程，并使用某个阈值来确定编辑是否足够小。准确地说，我们正在执行局部[序列对齐](http://en.wikipedia.org/wiki/Sequence_alignment)。该算法以其创造者 Smith-Waterman 的名字命名，并且因为它本质上是相同的，所以与 Levenshtein 算法具有相同的复杂性。

传统演示与 Levenshtein 和 Smith-Waterman 的唯一区别是我们之前提到的一些事情：为什么每次编辑都被赋予距离为一？相反，在 Smith-Waterman 演示中，我们假设有一个函数给出了我们的间隙分数，即，赋予每个字符对齐的值，即，匹配和编辑的分数，分数受生物学考虑驱动。当然，正如我们已经指出的那样，这种需要并不特有于生物学；我们完全可以利用“间隙分数”来反映基于键盘特性的替换可能性。

### 21.3.4 动态规划

我们已经使用备忘录作为保存过去计算值以供以后重用的标准方法。还有另一种称为动态规划的流行技术来实现这一点。这种技术与备忘录密切相关；事实上，它可以被视为实现相同目标的双重方法。首先我们将看到动态规划的工作原理，然后讨论它与备忘录的区别。

动态规划也是通过建立答案的记忆，并在需要时查找它们而不是重新计算它们。因此，它也是将计算形状从树转换为实际调用的 DAG 的过程。关键的区别在于，它不是从最大的计算开始并递归到较小的计算，而是从最小的计算开始，向外构建到较大的计算。

我们将在这种方法的指导下重新审视我们之前的例子。

### 21.3.4.1 动态规划的卡塔兰数

首先，我们需要定义一个数据结构来保存答案。按照惯例，我们将使用一个数组。当我们的空间不够用时会发生什么？我们可以使用我们在万圣节分析中学到的加倍技术。

```
MAX-CAT = 11

answers :: Array<Option<Number>> = array-of(none, MAX-CAT + 1)
```

接下来，catalan 函数只需在这个数组中查找答案：

```
fun catalan(n):
  cases (Option) array-get-now(answers, n):
    | none => raise("looking at uninitialized value")
    | some(v) => v
  end
end
```

但是我们如何填充数组呢？我们初始化一个已知值，并使用公式按顺序逐步计算其余部分：

```
fun fill-catalan(upper):
  array-set-now(answers, 0, some(1))
  when upper > 0:
    for map(n from range(1, upper + 1)):
      block:
        cat-at-n =
          for fold(acc from 0, k from range(0, n)):
            acc + (catalan(k) * catalan(n - 1 - k))
          end
        array-set-now(answers, n, some(cat-at-n))
      end
    end
  end
end

fill-catalan(MAX-CAT)
```

最终的程序遵循了<catalan-tests>中的测试。

请注意，我们不得不撤销自然的递归定义，—从较大的值到较小的值的递归—，改为使用从较小的值到较大的值的循环。原则上，程序存在一个危险，即当我们将卡塔兰应用到某个值时，答案的索引可能尚未初始化，从而导致错误。实际上，我们知道，因为我们在计算下一个较大值之前填充了所有较小的索引，所以我们永远不会真正遇到这个错误。请注意，这需要对我们的程序进行仔细的推理，而我们在使用备忘录时不需要进行这样的推理，因为在那里，我们精确地进行了所需的递归调用，它们要么查找值，要么重新计算它。

### 21.3.4.2 Levenshtein 距离和动态规划

现在让我们着手重写 Levenshtein 距离计算：<levenshtein-dp> ::=

|   fun levenshtein(s1 :: List<String>, s2 :: List<String>): |
| --- |
|     <levenshtein-dp/1> |
|   end |

我们将使用一个表示每个单词前缀的编辑距离的表。也就是说，我们将有一个二维表，行数等于 s1 的长度，列数等于 s2 的长度。在每个位置，我们将记录该位置处表中所代表的 s1 和 s2 的前缀的编辑距离。请注意，索引算术将是一个不断的负担：如果一个单词的长度为\(n\)，我们必须记录到其\(n + 1\)个位置的编辑距离，额外的一个对应于空单词。这对于两个单词都成立：<levenshtein-dp/1> ::=

|   s1-len = s1.length() |
| --- |
|   s2-len = s2.length() |
|   answers = array2d(s1-len + 1, s2-len + 1, none) |
|   <levenshtein-dp/2> |

注意，通过在 levenshtein 内部创建 answers，我们可以根据输入确定它需要的确切大小，而不是必须过度分配或动态增长数组。我们已经用 none 初始化了表，因此如果我们意外地尝试使用未初始化的条目，我们将收到错误消息。编写和调试此代码时证明是必要的！因此，创建让我们假设表只包含数字的辅助函数将是方便的：<levenshtein-dp/2> ::=

|   fun put(s1-idx :: Number, s2-idx :: Number, n :: Number): |
| --- |
|     answers.set(s1-idx, s2-idx, some(n)) |
|   end |
|   fun lookup(s1-idx :: Number, s2-idx :: Number) -> Number: |
|     a = answers.get(s1-idx, s2-idx) |
|     cases (Option) a: |
|       &#124; none => raise("looking at uninitialized value") |
|       &#124; some(v) => v |
|     end |
|   end |

现在我们必须填充数组。首先，我们初始化了当 s2 为空时的编辑距离的行，以及当 s1 为空时的列。在\((0, 0)\)，编辑距离为零；在之后的每个位置，它是该位置与零的距离，因为必须将这么多字符添加到一个单词或从另一个单词中删除才能使两个单词重合：<levenshtein-dp/3> ::=

|   for each(s1i from range(0, s1-len + 1)): |
| --- |
|     put(s1i, 0, s1i) |
|   end |
|   for each(s2i from range(0, s2-len + 1)): |
|     put(0, s2i, s2i) |
|   end |
|   <levenshtein-dp/4> |

现在我们终于来到了计算的核心。我们需要迭代每个单词中的每个字符。这些字符位于索引 0 到 s1-len - 1 和 s2-len - 1，这恰好是 range(0, s1-len)和 range(0, s2-len)产生的值范围。<levenshtein-dp/4> ::=

|   for each(s1i from range(0, s1-len)): |
| --- |
|     for each(s2i from range(0, s2-len)): |
|     <levenshtein-dp/compute-dist> |
|     end |
|   end |
|   <levenshtein-dp/get-result> |

注意，我们正在从小案例“向外”构建我们的方式，而不是从大输入开始，递归地“向下”工作到小案例。

> 现在做！
> 
> > 这严格来说是真的吗？

不，不是这样的。我们首先填写了表的“边界”值。这是因为在 <levenshtein-dp/compute-dist> 中间这样做会更加烦人。通过初始化所有已知值，我们保持了核心计算的简洁性。但这确实意味着我们填充表的顺序相当复杂。

现在，让我们返回计算距离。对于每一对位置，我们想要对包括那些位置的单词对的编辑距离。这个距离是通过检查这对位置上的字符是否相同来确定的。如果它们相同，则距离与前缀的前一对的距离相同；否则，我们必须尝试三种不同类型的编辑：<levenshtein-dp/compute-dist> ::=

|   距离 = |
| --- |
|     如果 index(s1, s1i) == index(s2, s2i)： |
|       查找(s1i, s2i) |
|     否则： |
|       min3( |
|         1 + 查找(s1i, s2i + 1) |
|         1 + 查找(s1i + 1, s2i) |
|         1 + 查找(s1i, s2i)) |
|     终点 |
|   put(s1i + 1, s2i + 1, dist) |

顺便说一下，在使用表格表示法时，这种“错位一”的坐标算术是传统的，因为我们的代码是根据本质上不存在的元素编写的，因此必须创建一个填充表来保存边界条件的值。另一种选择是允许表从 -1 开始寻址，以便主要计算看起来更传统。无论如何，当这个计算完成时，整个表都已填满了值。我们仍然必须读出答案，它位于表的末尾：<levenshtein-dp/get-result> ::=

|   查找(s1-len, s2-len) |
| --- |

即使不考虑我们编写的辅助函数来满足我们对使用未定义值的担忧，我们最终得到：至撰写本文时，[维基百科页面](http://en.wikipedia.org/w/index.php?title=Levenshtein_distance&oldid=581406185#Iterative_with_full_matrix) 上关于莱文斯坦距离的 [当前版本](http://en.wikipedia.org/wiki/Levenshtein_distance) 展示了一个与上述代码非常相似的动态规划版本。通过以伪代码编写，它避免了地址算术问题（注意单词是从 1 开始索引的，而不是从 0 开始，这使得代码的主体看起来更“正常”），并且通过将所有元素初始化为零，它允许了微妙的错误，因为一个未初始化的表元素与一个编辑距离为零的合法条目是无法区分的。该页面还展示了[递归](http://en.wikipedia.org/w/index.php?title=Levenshtein_distance&oldid=581406185#Recursive) 解决方案，并提到了记忆化，但没有展示代码。

```
fun levenshtein(s1 :: List<String>, s2 :: List<String>):
  s1-len = s1.length()
  s2-len = s2.length()
  answers = array2d(s1-len + 1, s2-len + 1, none)

  for each(s1i from range(0, s1-len + 1)):
    put(s1i, 0, s1i)
  end
  for each(s2i from range(0, s2-len + 1)):
    put(0, s2i, s2i)
  end

  for each(s1i from range(0, s1-len)):
    for each(s2i from range(0, s2-len)):
      dist =
        if index(s1, s1i) == index(s2, s2i):
          lookup(s1i, s2i)
        else:
          min3(
            1 + lookup(s1i, s2i + 1),
            1 + lookup(s1i + 1, s2i),
            1 + lookup(s1i, s2i))
        end
      put(s1i + 1, s2i + 1, dist)
    end
  end

  lookup(s1-len, s2-len)
end
```

这与记忆化版本（<levenshtein-memo>）值得对比。有关典型动态规划问题的更多示例，请参阅[此页面](http://people.csail.mit.edu/bdean/6.046/dp/)，并思考如何将每个问题表示为直接递归。

### 21.3.5 记忆化和动态规划的对比

现在我们已经看到了两种避免重新计算的技术，值得对它们进行对比。值得注意的是，记忆化是一种更简单的技术：编写自然递归定义；确定其空间复杂度；决定是否存在足够的问题以值得进行空间-时间折衷；如果有必要，应用记忆化。代码保持清晰，后续的读者和维护者会对此表示感谢。相比之下，动态规划需要重新组织算法以自底向上工作，这往往会使代码更难以理解，并且充满了关于边界条件和计算顺序的微妙不变量。

话虽如此，动态规划解决方案有时可能更加计算效率高。例如，在莱文斯坦案例中，注意到在每个表元素中，我们（最多）仅使用来自前一行和前一列的元素。这意味着我们从不需要存储整个表；我们只需保留表的边缘，这将空间降低到长度之和，而不是长度之积。在计算生物学环境中（例如使用 Smith-Waterman），这种节省可能是相当大的。这种优化对于记忆化来说基本上是不可能的。

更详细地说，这里是对比：

| 记忆化 |  | 动态规划 |
| --- | --- | --- |
| 自顶向下 |  | 自底向上 |
| 深度优先 |  | 广度优先 |
| 黑盒 |  | 需要代码重组 |
| 所有存储的调用都是必要的 |  | 可能会进行不必要的计算 |
| 无法轻易消除不必要的数据 |  | 可以更容易地消除不必要的数据 |
| 永远不会意外使用未初始化的答案 |  | 可能会意外使用未初始化的答案 |
| 需要检查是否存在答案 |  | 可以设计为无需检查是否存在答案 |

正如这个表所表明的那样，这些基本上是对偶方法。在大多数动态规划描述中可能没有明确说明的是，它也是建立在对于给定输入始终产生相同答案的计算的假设上，即，它是一个纯函数。

从软件设计的角度来看，还有两个考虑因素。

首先，当记忆化解决方案使用通用数据结构来存储备忘录表时，其性能可能落后于动态规划，而动态规划解决方案无论如何都将使用自定义数据结构（因为代码需要根据其重新编写）。因此，在出于性能原因切换到动态规划之前，尝试为问题创建一个自定义的记忆器是有道理的：动态规划版本中所体现的相同知识通常可以编码到这个自定义的记忆器中（例如，使用数组而不是列表来提高访问速度）。这样，程序可以在保留可读性和可维护性的同时享受与动态规划相媲美的速度。

其次，假设空间是一个重要的考虑因素，并且动态规划版本可以使用显著较少的空间。那么使用动态规划确实是有意义的。这是否意味着记忆化版本无用？

> 现在开始！
> 
> > 你觉得呢？我们还需要记忆化版本吗？

是的，当然了！它可以作为动态规划版本的参考 oracle，因为两者应该产生相同的答案——<wbr>而记忆化版本将是一个比纯递归实现更高效的 oracle，因此可以用于测试更大输入上的动态规划版本。

简而言之，始终先生成记忆化版本。如果需要更高的性能，请考虑定制化记忆器的数据结构。如果还需要节省空间，并且可以得到更节省空间的动态规划解决方案，那么请保留两个版本，使用前者测试后者（继承您代码并需要更改它的人会感谢您！）。

> 练习
> 
> > 我们已经将记忆化和动态规划之间的根本区别描述为自顶向下，深度优先和自底向上，广度优先计算之间的区别。这自然会引发一个问题，那就是：
> > 
> > +   自顶向下，广度优先
> > +   
> > +   自底向上，深度优先
> > +   
> > 计算顺序。它们也有特殊的名称吗，我们只是碰巧不知道吗？它们不重要吗？还是由于某种原因而没有讨论？
